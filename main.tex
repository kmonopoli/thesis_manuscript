\documentclass{report}
% \documentclass{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%% FOR EXTRA SUBSECTIONS %%%%%%%%%%%%%%
\usepackage{titlesec}
\setcounter{secnumdepth}{4}
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{graphicx} % Required for inserting images
\usepackage{setspace}
\doublespacing

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%% FOR CITATIONS %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[
backend=biber,
style=alphabetic,
sorting=ynt
]{biblatex}
\addbibresource{references.bib}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%  NOTES and TODOs  %%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 1) update references for Semi-supervised paper
% 2) Check that have all sections needed for thesis per guidelines (ex: need an abstract!)
%
% •	When you are writing an introduction make sure you have key figures to demonstrate the concepts. Also make sure that it written in the way to formulate the key scientific quesiton, need to be adressed, you hypothesis and serves to the content of the thesis
%
% •	TODO: when discussing modifications also mention relevance of duplex structure 
%
% •	Possibly move around sections of thesis to include some parts of my work (especially my collaborative work) in the introduction/background (not sure? Ask AK/Committee)
%
% •	To future directions: add RNA structure/folding component 
%
% •	Maybe consider combining introductions from each of the papers included in the manuscript? 
%
% •	TODO: check through introduction sections of each paper included in thesis to be sure touch on all points mentioned
%
% •	TODO: is human Ago2 all capitalized?
%
% 
% 
% 
% 
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%       NOTES      %%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% * = From Monopoli et al., MTNA 2023
% † = From Monopoli et al., (in preparation for submission) 2025 
% ‡ = From Shmushkovich and Monopoli et al., NAR 2018}}
% ** = From Davis et al., 2024 (under review with NAR)
% *** = From Hariharan et al., PNAS 2023}}
% 
% 
% 
% % % -1 \part{part}
% 0 \chapter{chapter}
% 1 \section{section}
% 2 \subsection{subsection}
% 3 \subsubsection{subsubsection}
% 4 \paragraph{paragraph}
% 5 \subparagraph{subparagraph}
% 
%%%%%%  END:  NOTES and TODOs  %%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%  FOR INSERTING TEXT  %%%%%% 
% Figure‡ 2
% Figure \ref{fig:Figure‡ 2}
% ______________________
% 5′
% $5^\prime$
% _______________
% 3′
% $3^\prime$
% ____________
% 2′
% $2^\prime$
% ____________
% K\textsuperscript{th}
% $K^{th}$
% __________________
% 1/10\textsuperscript{th}
% 9/10\textsuperscript{ths}
% __________________
% AUCPR\textsubscript{adj}
% $AUCPR_{adj}$
% _______________
% <24%
% $<24\%$
% _________________
% ~
% $\sim$
% _________________
% ∼
% $\sim$
% _________________
% 40%
% $40\%$ 
% ___________________
% ≤
% \leq
% _________
% ≥
% \geq
% _________
% h\textsubscript{1}
% $h\textsubscript{1}$
% _________________
% \textsubscript{2}
% _2
% ______________
% AUCPR\textsubscript{adj }
% $AUCPR_{adj}$
% ___________________
% AUCPR\textsubscript{adj}
% $AUCPR_{adj}$
% ___________________
% P\textsubscript{R=1}
% $P_{R=1}$
% _________________
% AUCPRadj
% $AUCPR_{adj}$
%%%%%%  END: FOR INSERTING TEXT  %%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\title{Machine learning and artificial intelligence applications to therapeutic siRNA design}
\author{Kathryn Monopoli }
\date{2025}


\begin{document}

\maketitle

\tableofcontents


\section{TODO:ABSTRACT}




\chapter{INTRODUCTION}

Small interfering RNAs (siRNAs) are a coming of age drug with XXX currently approved an many more in the clinical pipeline. Harnessing the power of RNA interference (RNAi), these small RNA drugs have great potency and specificity for any gene, providing them with a vast application potential to treat a multitude of diseases. Recent advances in chemistry and the optimization of fully chemically modified siRNAs have driven a boom in siRNA drug development (list drugs) (REF). While the targeting mechanism of siRNAs is relatively straightforward following the decades-old knowledge of RNAi (REF mello paper, ambros, others?), in practice/actuality developing an siRNA that potently silences its target transcript remains a challenge (REFs). Even with optimization of known components,(Reynolds et al. 2004) sequence complementarity alone does not ensure silencing potency (Figure \ref{fig:Figure+ siRNAs ranging efficacies multiple target genes}). While factors driving the efficacy of siRNAs has been studied at small (often target-specific) scale (REFs), their ubiquitous mechanism enables (and their more general application requires) large-scale high-throughput efficacy evaluation and studies best suited for computational evaluation and modeling. For this computational models developed for siRNA efficacy prediction have been built. Unfortunately, no existing models prove to be reliable for identifying functional, therapeutic siRNAs. Limitations in data applied and models employed, among others, have hindered the success. With advances in computing power technology in step with advanced statistical models and artificial intelligence algorithms, opens a vast door to possibilities to solve problems and study mechanisms in biology computationally. Furthermore, to make these models practically usable in design of siRNA, they must be incorporated into algorithms purposely built for the design and identification of potent siRNAs. While such algorithms exist, even excluding the fact that their implemented models have limited predictive power, many of these algorithms have limited access due to requirement of computational programming skills to implement, rather than providing an accessible graphical user interface. 

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{BACKGROUND FIGURE siRNAs multiple targets.png}
    \caption{TODO: Enter Caption, efficacies are normalized by max-min}
    \label{fig:Figure+ siRNAs ranging efficacies multiple target genes}
\end{figure}

\section{siRNA Therapeutics History and Development} % (AK said to condense this subsection to 1 page)
\subsection{RNA interference}

RNA interference (RNAi) is a biological process in which (usually) double-stranded RNA drives the sequence-specific suppression of gene expression. A phenomenon first formally reported in petunias (Napoli, Lemieux, and Jorgensen 1990) and later explained by Fire and Mello through work in C elegans (Fire et al. 1998), RNAi is a phenomenon broadly present across many eukaryotes (with some exception, that can typically be overcome by genetic engineering) making it a powerful tool for both research and therapeutics. The two molecules most commonly involved in RNAi are microRNAs (miRNAs) and small interfering RNAs (siRNAs). miRNAs are small (21-23nt), single-stranded (but derived from a hairpin precursor), noncoding RNAs that are endogenously expressed and frequently play a regulatory function by suppressing gene expression (REFs). The first miRNA, lin-4, was discovered by a group led by Victor Ambros in 1993 (REF). In animals, miRNAs typically recognize their target through a short (8nt?) seed region, inducing repression of the target transcript (REF). More commonly exogenously derived, small interfering RNAs (siRNAs) are $\sim$20nt double-stranded RNAs. Typically, siRNAs recognize their target through a longer $\sim$16nt region, often inducing target gene silencing by directing cleavage of a target mRNA transcript (REF). Both miRNA and siRNA have similar mechanisms and utilize most of the same RNAi machinery in the cell, primarily by incorporating into an Argonaute-containing complex to produce the RNA-induced silencing complex (RISC) (REFs). The RISC complex can then bind to target mRNA transcripts based on complementarity to the sequence of the miRNA or siRNA guide strand, and lead to suppression of translation and/or degradation of the target mRNA transcript (REF). Synthetic siRNAs can be introduced to cells exogenously to induce highly specific, and potent, target gene knockdown, making them valuable therapeutic tools (REF).

\subsection{siRNA Background}

The mechanism of RNAi induced by siRNA is presented in Figure+  \ref{fig:Figure+ siRNA-RISC mechanism background}. Exogenous siRNAs can be introduced to cells (REF), and once inside the cell can be loaded into a protein complex containing Argonaute (REF). One of the strands of the siRNA is cleaved (REF), and the mature RNA-induced silencing complex (or RISC) is formed with a single strand of the siRNA (REF). The RISC complex can then bind target mRNAs through complementary base pairing. Argonaute can then cleave the target mRNA, and the mRNA is degraded in the cytoplasm. The RISC is then recycled. 

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{BACKGROUND FIGURE siRNA-RISC Mechanism.png}
    \caption{Small interfering RNAs (siRNA) are small, approximately 20nt double-stranded RNAs that can be added to cells and once inside the cell can be loaded into a protein complex containing Argonaute. The passenger (sense) strand of the siRNA is cleaved, and the mature RNA-induced silencing complex (RISC) is formed with the guide (antisense) strand of the siRNA. The RISC complex can then bind target mRNAs through complementary base pairing. Argonaute can then cleave the mRNA and the mRNA is degraded in the cytoplasm leading to suppression of the target gene expression. The RISC is then recycled. }
    \label{fig:Figure+ siRNA-RISC mechanism background}
\end{figure}




An siRNAs specificity lies primarily in the sequence of their seed region, defined here as positions X-Y (REF) (Figure+ \ref{fig:Figure+ RISC targeting positions numbered}). This region interacts with the target mRNA through complementary base pairing (REF) along with additional supplementary base paring (the anchor, seed, central, $3^\prime$ supplementary and tail regions)  for siRNA-directed target cleavage. The $\sim$20nt region on the target mRNA that interacts directly with RISC is defined here as the target site (Figure+ Z). The target site sequence plays a major role in siRNA efficacy (REFs) and is described in greater detail in the next chapter. 

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{BACKGROUND FIGURE RISC-targeting_positions_numbered.png}
    \caption{TODO:Enter Caption}
    \label{fig:Figure+ RISC targeting positions numbered}
\end{figure}


\subsection{siRNAs as Therapeutics}

The ubiquity of the siRNA mechanism in humans (REF) makes it valuable tool for therapeutic development. Theoretically, nearly any transcript can be targeted by an siRNA to control a gene’s expression, providing a wide range of disease therapeutic applications. As informational drugs fully modified therapeutic siRNAs are tunable such that they can be (at least partially) functionally separated into two components: the targeting specificity component (the pharmacophore) and the component dictating its pharmacokinetic properties and distribution (the dianophore) (REF SD thesis 37). Thus, while the drug can optimized for proper drug chemistry (delivery, distribution, safety, stability, metabolization, etc.), the targeting component can be tuned somewhat separately to the sequence of interest to target specific genes involved in a therapeutic target. This enables quick/efficient design of a therapeutic agent with high specificity while having a lot of flexibility. Their ability to target disease through nature’s “common pathway” of nucleic acid language makes them highly flexible making their target and disease repertoire virtually endless.


\subsubsection{Initial therapeutic development with nonmodified and partially modified siRNAs}
Upon discovery of RNAi, development of siRNA drugs began shortly and rapidly after (Titze-de-Almeida, David, and Titze-de-Almeida 2017; Bumcrot et al. 2006; Jürgen Soutschek 2004; Kumar 2010; Song 2005; Palliser 2006; Li SARS-Coronovirus Nat Med 2005; Song 2003). Unfortunately, early drug development faced many setbacks. Early siRNA drugs faced major challenges with delivery, with only those that could be delivered locally finding any traction (REF Zhang J Biol Chem 2004; Woodrow 2009; Tan 2005; Nakamura 2004; Shen 2006; Reich 2003). Instability of these nonmodified or limitedly modified siRNAs (REF Layzer 2004) meant narrow therapeutic windows requiring higher doses risking increased toxicity. Additional challenges included immunogenicity (REF Sledz 2003; Marques and Williams 2005; Judge 2005; Hornung 2005), and off-targeting (REF Jackson 2003; Kariko 2004; Jackson 2006). These challenges along with overall limited efficacy of naked compounds lead to a drop-off in siRNA therapeutic development in the early 2010’s (REF Ledford 2010; Schmidt 2011; Lundin 2011).

% REFs for clinical trials:
% 1.	Opko Health. Opko health announces update on phase III clinical trial of bevasiranib. http://investor.opko.com/releasedetail.cfm?ReleaseID=369294 (Opko Health, 6 March 2009).
% 2.	Alnylam Pharmaceuticals. Alnylam and Cubist announce complete data from phase II study of ALN-RSV01 in lung transplants patients naturally infected with respiratory syncytial virus http://phx.corporate-ir.net/preview/phoenix.zhtml?c=148005&p=irol-newsArticle&ID=1308924&highlight= (Alnylam Pharmaceuticals, 20 July 2009).
% 3.	Macron, D. Pfizer to shut down oligo therapeutics unit as part of restructuring. Gene Silencing News http://www.genomeweb.com/rnai/pfizer-shut-down-oligo-therapeutics-unit-part-restructuring (3 February 2011).


\subsubsection{Later therapeutic development with fully modified siRNAs}
It was not until chemical modifications were optimized did siRNA therapeutics did gain any traction in the clinic (Khvorova and Watts, 2017; Hayden 2014; Egli and Manoharan 2023). Introducing backbone phosphorothioate modifications along with $2^\prime$ ribose modifications $2^\prime$-O-methyl and $2^\prime$-fluoro overcame many challenges in stability and degradation (Monia 1996; Choung 2006; Robbins 2007; Manoharan 2011; Khvorova and Watts, 2017). Hydrophobic conjugates (in the context of this thesis a Cholesterol-TEG linker) support improved delivery into cells (REF Hassler?; Nikan 2016). Earlier work indicated the importance of a $5^\prime$ Phosphate on the guide strand for RISC recognition (Martinez 2002; Ma 2005). These modifications are applied to all the siRNAs utilized in this thesis work, with all chemical scaffolds shown in Figure \ref{fig:Figure+ chemical modification patterns}. Hope for successful systemic delivery came with lipid nanoparticles in 2010 (REF Davis - Evidence of RNAi in humans from systemically administered siRNA via targeted nanoparticles) and later with N-acetylgalactosamine (GalNAc) conjugation (Nair 2014). These advances along with many others, culminated the major milestone approval of the first siRNA drug, Patisiran in 2018 (Adams NEJM 2018). Currently there are six FDA approved siRNA drugs with many more in development. 



\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{BACKGROUND FIGURE - chemical modifications.png}
    \caption[TODO: shorter figure title]{TODO: figure caption}
    \label{fig:Figure+ chemical modification patterns}
\end{figure}


\subsection{Nonmodified siRNAs and the Limits of Legacy Models}
With this early growth in interest in siRNAs as therapeutics, came the need for methods to design these drugs. Thus during this height of excitement in siRNA therapeutics during the early 2000’s led to a large growth in siRNA design model development with the publication of many papers on the topic (REFS MANY siRNA design papers from before 2010). While this growth was valuable in gaining insight into mechanisms, particularly for studies employing wet lab confirmation of their models, which additionally provided the field with additional validated siRNA efficacy data (REFS papers like AK’s and Huesken where they actually evaluate things). Many of these works sought to apply existing data to build models (REFs OLDER papers that use data but don’t actually produce any themselves), and even more such studies are still frequently performed (REFs NEWER papers that use data but don’t actually produce any themselves). The impact of these very necessary chemical modifications on siRNA efficacy is well known (REFS same as papers above), as described in the above section, these modifications have therefore been incredibly valuable, but also added an additional variable to the siRNA efficacy prediction question. In fact it is clear these chemical modifications have a major impact on predictions such that models developed using nonmodified siRNAs are not predictive on modified and vice versa (see REF Chapter XX, REF Figure Y; REFShmushkovic 2018). Thus with these modifications comes a need for a new wave of siRNA efficacy prediction models and design algorithms that are purpose-made for therapeutic, fully-modified siRNAs lest we continue down this path of painfully slow siRNA design and development marred by difficulty in identifying potent fully-modified targets in the early stages of therapeutic development. More studies on the impacts of various modifications on siRNA efficacy prediction need to be performed, but the evidence is clear that continuing development without considering the significant impacts of these necessary modifications on siRNA efficacy is not productive. 



\section{siRNA Design Background}
\subsection{Discovery of Important Components of siRNA}
\subsubsection{Discovery of siRNA As a $\sim20nt$ Duplex}

Following the discovery that double-stranded RNA (dsRNA) could induce gene silencing (Fire et al. 1998), early hypotheses proposed that dsRNA unwound in the cell, allowing the antisense strand to pair with target mRNA and promote its degradation. However, full-length antisense strands were not detected intracellularly, prompting further investigation. Short interfering RNAs (siRNAs) were first identified in plants as 21–23 nucleotide fragments derived from dsRNA (Hamilton and Baulcombe 1999). These findings were extended in Drosophila lysates, where dsRNA was shown to be processed into short fragments that directed sequence-specific mRNA cleavage (Zamore et al. 2000). Subsequent studies confirmed the presence of similarly sized RNA fragments in cells exposed to dsRNA dsRNA (Hammond et al. 2000; Parrish et al. 2000; Yang, Lu, and Erickson 2000). Tuschl and colleagues later demonstrated that these 21–22 nucleotide duplexes are the active agents mediating RNA interference (Elbashir et al. 2001; 2001).


\subsubsection{Development of understanding of the seed}

When characterizing the siRNA as a $\sim$21 nt duplex, Elbashir et al. (2001) observed that not all nucleotide positions contributed equally to target recognition. Subsequent studies revealed that siRNAs containing mismatches could repress translation in a manner reminiscent of microRNAs (miRNAs), suggesting positional differences in base-pairing importance (Doench et al. 2003; Saxena et al. 2003; Zeng et al. 2003). In 2004, Doench and Sharp demonstrated that target repression by miRNAs was primarily driven by the first 8 nucleotides of the guide strand, a region later termed the “seed” (Doench and Sharp 2004). This was further supported by kinetic analyses from Haley and Zamore, who found that bases at the $5^\prime$ end of the siRNA guide strand were critical for target binding (Haley and Zamore 2004). Earlier work by Lewis et al. (2003) helped define the concept of seed pairing in miRNA-mediated target recognition, showing that nucleotides 2–7/8 were key to specificity—an insight that would later prove relevant to siRNA off-targeting. This connection was reinforced by transcriptome-wide profiling studies demonstrating that siRNAs can elicit off-target repression via seed complementarity in the $3^\prime$ UTR of unintended mRNAs (Jackson et al. 2003; Birmingham et al. 2006; Jackson et al. 2006). Together, these findings established the seed region as a central determinant of both siRNA efficacy and specificity. 


\subsubsection{Discovery of the thermodynamic bias}

A pivotal discovery in siRNA design was the identification of thermodynamic asymmetry within the siRNA duplex, first reported by Khvorova et al. in 2003 (Khvorova, Reynolds, and Jayasena 2003). This principle states that the strand with a less stable (i.e., more weakly paired) $5^\prime$ end is preferentially incorporated into Argonaute as the guide strand. Consequently, the relative stability of the duplex ends determines strand selection. This finding was corroborated by Schwarz et al. (2003), who demonstrated similar strand bias in Drosophila embryo lysates based on $5^\prime$ end thermodynamic stability (Schwarz et al. 2003).

\subsection{siRNA Efficacy Prediction}

Designing siRNAs that potently silence their target has remained a challenge, and through the years developments have made small gains in this area. Simply designing siRNAs with full complementarity to their target is not sufficient to ensure potent knockdown. For example, many siRNAs targeting the same transcript show wide ranges in silencing efficacies (Figure \ref{fig:Figure+ siRNAs ranging efficacies multiple target genes}). Putting aside the additional critical features beyond efficacy required for functional siRNAs (low GC content, excluding polynucleotide stretches, sufficient uniqueness to avoiding off-targeting, etc.) which are discussed in greater detail later in this chapter \ref{sec:other sirna parameters}, designing an siRNA that silences its target with high potency, is a challenge that has undergone much investigation through the development and history of siRNA therapeutic research.
 
The pursuit of elucidating this process and enabling the efficient selection of potent siRNAs, has produced many protocols for selecting potent siRNAs. These protocols range in structure and simplicity from simple rules, to application of predictive mathematical models, to complex software for designing and predicting potent siRNAs. We explore these in some detail here, focusing on some of the major players and advances, though this exploration is in not intended to be comprehensive.


\subsubsection{Early Rule-Based siRNA Prediction Models}

Initial siRNA design protocols developed from rules through discoveries presented across the field (REF several papers), however a few key studies provide rules that specifically outline siRNA design protocols. Rather than complex computational models/algorithm frameworks, some of the earliest methods primarily were presented as simple rules for siRNA design, many of which are still applied today, often incorporated as a first line filter for more powerful predictive models. Note, however, that with the utilization of heavy chemical modification, some early rules/guidelines are less relevant in the current state of siRNA design (REF). 

The rules presented by Ui-Tei et al. in 2004 propose position-specific base guidelines for efficient siRNAs ($5^\prime$ A/U on the guide strand, $5^\prime$ G/C on the passenger strand, high A/U content in the $5^\prime$ third of the guide, no CG stretches greater than 9nt) (REF Ui-Tei et al., Nucleic Acids Research, 2004.). The rules presented by Amarzguioui and Prydz (REF ) included asymmetry in stability of the duplex ends and base preferences (including absence of U at position 1 and G at position 19 of the sense strand, and presence of C at position 1). These studies applied to generate these rules often had major limitations, namely dataset size, different siRNA duplex lengths, and primarily reporter-based siRNA data (rather than endogenous), though many of the rules show general agreement across the methods for identifying functional siRNAs. These rule-based methods alone, however, were typically not sufficient for identifying potent siRNAs in an efficient way (i.e., without screening many siRNAs for a single target). Furthermore, application of these rules was not simple as they needed to be employed manually, where a computational tool would speed the process.

DEQOR was one of the first fully end-to-end computational algorithms for siRNA design that was presented on the web as a (now defunct) webportal (REF Henschel et al., Nucleic Acids Research, 2004.). DEQOR incorporated very simple position base rules along with a cross-reactivity search employing BLAST, but was geared primarily towards developing endoribonuclease-prepared siRNAs, and was not developed with or evaluated on an siRNA dataset, but simply employed rules for siRNA design known at the time, thus the utility and veracity for general siRNA design is likely limited.




\paragraph{siDirect focuses on minimizing off-targeting}  %(TODO: maybe move to different section? or mention these models here but go into detail about their off-targeting components in later section?)
With incorporation of off-targeting searches into these algorithms, siDirect presented an important advancement in rule-based siRNA design was introduced with (REF siDirect 1.0 Naito et al., Nucleic Acids Research, 2004), which implemented a custom off-target filtering algorithm in place of the commonly used BLAST-based approaches (e.g., REF DEQOR). This represented a major step forward, as BLAST is optimized for identifying regions of sequence homology, whereas siRNA off-targeting—particularly through the seed region—often involves exact or near-exact matches. Because both require transcriptome-wide searches, the use of RNAi-specific algorithms is essential not only for ensuring safety by minimizing off-target effects, but also for maintaining computational efficiency through domain-appropriate optimization. To quantify specificity, siDirect introduced the metric “mismatch tolerance,” which counts the number of mismatches between the siRNA and potential off-target transcripts. This was calculated using the Smith-Waterman local alignment algorithm, which, though slower than BLAST, was chosen for its accuracy in capturing exact match requirements. The authors also addressed the complexity introduced by alternative splicing by constructing a non-redundant set of duplicate-free exons to reduce computational redundancy. While this strategy was well-suited to the computational constraints of the time, later work has shifted toward searching the full transcriptome—including all annotated splice variants—treating isoforms from the same gene as equivalent to avoid falsely labeling them as off-targets (REF – FIND PAPER THAT USES ALL REFSEQ). With modern computing power, this more comprehensive approach offers improved adaptability to updated sequencing datasets and better reflects the biological complexity of gene expression. siDirect was presented as a webportal, and the group further updated this tool to include consideration of thermodynamic stability of the see-target duplex producing siDirect 2.0, which is still accessible on the web (https://sidirect2.rnai.jp/; REF siDirect 2.0 Naito et al., BMC Bioinformatics, 2009).  


\subsubsection{Linear siRNA Design Models}
The discrete and sequential nature of the target sequence makes siRNA design particularly amenable to predictive modeling. Among the earliest and most widely adopted approaches were linear models, which offer advantages in simplicity, interpretability, and computational efficiency. These models focus primarily on sequence-specific features while sometimes incorporating simple rule-based scoring described in the previous section. Mathematical modeling is made easier with larger datasets, but the low throughput and cost of evaluating siRNA efficacy makes this a challenge, despite this, several early linear models were generated using limited datasets. The same group that uncovered the thermodynamic bias presented their own set of heuristic rules and positional base preferences which they incorporated into a scoring scheme for identifying potent siRNAs (REF  Reynolds et al., Nature Biotechnology, 2004.). These rules were developed using an efficacy-probability-based sorting model to generate positional base preferences, and achieved remarkably high accuracy given the limited dataset size (180 siRNAs). 

Observing a periodic effect in efficacies dependent on transcript target position of 702 siRNAs Kato and Suzuki developed siExplorer, which incorporates this phenomenon into a linear model to predict siRNA efficacy and was presented as a simple web portal that is still accessible (https://rna.chem.t.u-tokyo.ac.jp/cgi/siexplorer.htm) (REF Katoh and Suzuki, NAR, 2007).
 
Applying a previously published large 2,182 siRNA dataset published by Huesken et al. (REF huesken), Ichihara et al. released i-Score, a linear regression-based model utilizing position-base preferences and duplex thermostability, which they released as an Excel VBA program i-Score designer (REF  Ichihara et al., Nucleic Acids Research, 2007.) Other algorithms including DSIR and siRNA Scales also present combined scoring methods including basic rules along with linear regression algorithms trained on base preferences, both were presented as, now defunct, web portals (REF Vert et al., Bioinformatics, 2006, REF Mateeva et al., NAR, 2007)

With advances in computation power and artificial intelligence, linear models have generally been overlooked with preference for machine learning models, however their simplicity and interpretability still make them incredibly valuable for early model development. In fact much of our recent work involved developing linear models for siRNA efficacy prediction, and we show the power and utility of such models particularly in the case of limited datasets (REF Shmushkovich and Monopoli; REF NAR; Monopoli et al., MTNA). Furthermore, the ease of interpretation of a linear model makes them excellent as techniques for early study of the data, they can be applied to easily identify base preferences and other trends in the data which can be valuable for downstream advanced model selection or optimization.



\subsubsection{Advanced Machine Learning-Based siRNA Design Models}

With advances in high throughput computing and the rise of artificial intelligence, machine learning (ML) techniques have become increasingly popular for siRNA design. One of the earliest and most influential examples was BIOPREDsi, published in 2005 by a group at Novartis (Huesken et al., 2005), which employed a shallow artificial neural network trained on silencing data from siRNAs targeting ectopically expressed reporter genes. While the model architecture is now outdated, superseded by deep learning approaches with greater capacity to capture complex patterns (REF Neural Network Background; see Chapter XYZ), this work marked a turning point in the field. Its likely most significant contribution was the publication of the first large-scale, homogeneously evaluated siRNA efficacy dataset, comprising of 2,182 siRNAs evaluated in using a high-throughput reporter-based assay.

Several other early models also applied classical ML methods. ThermoComposition21 incorporated thermodynamic features alongside sequence data in a shallow neural network (Shabalina et al., 2006), while Lu and Mathews utilized support vector machines trained on both sequence features and target site accessibility (Lu and Mathews, 2008). MysiRNA also utilized a multi-layer neural network trained incorporating existing models with whole stacking free energy (Mysara et al., 2011). siPRED utilizes support vector regression in tandem with a neural network (Pan, Chen, and Chu 2011). While not exhaustive, these examples illustrate early efforts to leverage ML for siRNA efficacy prediction. However, despite the proliferation of such models, many remain accessible only as code repositories requiring advanced computational expertise, and relatively few have undergone experimental validation to assess real-world utility.

The impact of the Huesken et al. work extends far beyond the BIOPREDsi model. Their dataset has been widely reused across hundreds of modeling studies, making it a foundational resource for siRNA prediction. Yet, this enduring influence is both a strength and a limitation. Although pivotal, the dataset lacks features critical for modeling modern therapeutic siRNAs—it consists entirely of unmodified siRNAs, evaluated in ectopic reporter systems, and represents a limited target space. This dataset is being utilized even as recently as 2024 with the publication of OligoFormer, which employs a language learning model (LLM) where the Huesken dataset makes up nearly 70\% of the data utilized. Applying increasingly sophisticated algorithms to this constrained dataset has yielded diminishing returns in predictive accuracy and relevance. As a result, many models prioritize moderate siRNAs with minimal translational value.

This over-reliance on a single, outdated dataset has contributed to a fragmentation of tools available to the field. Researchers today must often choose between commercial tools with opaque algorithms, difficult-to-implement academic models built on outdated data, or legacy models with user-friendly interfaces but limited applicability to modern therapeutic contexts. Together, these issues highlight the need for updated, biologically informed, and experimentally validated models that reflect the complexity and specificity required for therapeutic siRNA development.


\subsubsection{Data sources for siRNA efficacy prediction models:  Endogenous Targeting vs. Reporter Assays}

Further complicating these components are the data, while when acting as a therapeutic, siRNAs are ultimately designed to target endogenous transcripts, however typically siRNA efficacy is evaluated by proxy utilizing an artificial reporter plasmid. (TODO: briefly describe reporter assay and cite things as needed – see SD thesis for description). In fact, of all the major siRNA datasets employed for model building in the literature, XX of YY are reporter evaluated, and only ZZZ\% are derived from endogenous transcript knockdown (REFs all papers with siRNA efficacy data). Reporter assays remove an important component of the RISC-siRNA mechanism: the actual target transcript, and thus miss many important features encapsulated in this process. Consequently, it has been seen that siRNAs that are functional in a reporter assay are not functional in their native context (Figure+ X: TODO: figure from sarah Davis paper). 

To evaluate native or endogenous transcript knockdown common assays performed include qPCR and branch DNA assays (REFs). These assays measure endogenous effects of the siRNA on the natively expressed transcript by measuring the amount of target transcript present (and thus any decrease in native transcript levels upon treatment with siRNA). The bDNA assay works thusly (TODO: briefly describe bDNA assay). The qPCR assay for siRNA efficacy measurement works thusly (TODO: briefly describe qPCR siRNA assay). There are limitations to qPCR (TODO: list limitations of qPCR for siRNA measurements) and thus bDNA is often considered the “gold standard” for siRNA efficacy measurement. Unfortunately, the relative low throughput and high cost of bDNA assays limits their use. Measuring siRNA efficacy using any of these assays is relatively low throughput and expensive to perform, so large, high-quality datasets are not publicly available in the literature. 

Note still that reporter-derived siRNA efficacy data is incredibly valuable as it provides information regarding target sequence detection, binding, and cleavage (REFs) while being abstracted from target transcript-driven effects including accessibility driving RISC entry as well as availability due to expression (REFs) (TODO: confirm these effects-see intros of papers written with AK). In the context of biological mechanism, it is clear features outside of simply the target site play a critical role, however (REFs smushkovich 2018 and other papers – see early slide on TRAC meetings), and thus using reporter-derived data alone is not sufficient to encapsulate the target transcript-specific phenomenon. Thus to build the most accurate models, utilization of data sourced from endogenously evaluated siRNA is critical. Unfortunately no large databases of such data has been available publicly, however in this work we present such a dataset which we use to build highly predictive siRNA efficacy models (see Chapter TODO:XYZ).




\subsection{Parameters beyond efficacy important to siRNA design}\label{sec:other sirna parameters} 
While target silencing efficacy remains central to siRNA design, several additional sequence features significantly influence functionality. With therapeutic fully modified siRNAs concerns regarding sequence-specific thermodynamic properties such as those presented by Khvorova et al. (2003) REF are lessened, however overall GC content should remain below 60\% to prevent impairments in silencing (“A Protocol for Designing siRNAs with High Functionality and Specificity | Nature Protocols,” n.d.).
Effective targeting also requires that the siRNA is designed to target regions transcribed in the mature mRNA. Sequence information used in design therefore must employ transcriptomic rather than genomic data. This can be particularly challenging in the case of non-model organisms where high-quality, annotated, and regularly updated sequence information is often lacking. Moreover, accurate splice isoform annotation is crucial, and identifying the proper cell lines for screening endogenous knockdown is important. For instance, Alterman et al. observed limited silencing when targeting the $3^\prime$ UTR of the HTT gene due to omission of that region in the dominant isoform expressed in their cell line (REF Sarah Davis Thesis 30). 

Another vital consideration is to avoid siRNA sequences that inadvertently mimic endogenous miRNA seed regions. This requires species-specific miRNA seed databases such as miRBase and MirGeneDB. Unfortunately, these databases are often incomplete or unreliable for lesser-studied species.

Target specificity further depends on sequence uniqueness across the transcriptome. Positions corresponding to nucleotides 2–17 of the guide (which align to target positions 4–19) (Figure \ref{fig:Figure+ RISC targeting positions numbered}) must not match other transcripts. This requires comprehensive homology searches across hundreds of thousands of transcripts in the transcriptome, a computationally expensive task. Some tools, such as siDirect, mitigate this by using BLAST for off-target checking (REF siDirect), however BLAST is optimized for general sequence homology, not siRNA-specific complementarity, potentially overlooking near-perfect matches (REF 2nd siAlgorithm paper that mentioned this limitation of siDirect). Dedicated algorithms can enhance target specificity by minimizing seed complement frequency, but require extensive algorithmic tuning to perform in a computationally tractable way. In this thesis such an algorithm is presented in REF Chapter XYZ.

From a synthetic chemistry standpoint, siRNA sequences must also be readily synthesizable. Avoiding long stretches of the same nucleotide (GGGG, CCCC, UUUU, AAAA) is essential, as these can hinder chemical synthesis (REF). Palindromic regions are similarly problematic, as they may form hairpins that compromise duplex formation and lower yield (REFs).
Incorporating most of these components into siRNA design is relatively straightforward if performed computationally as an additional step in a algorithmic design following scoring. The only major limitations are regarding cross-reactivity and miRNA seed searches, where additional computational optimization of the algorithm is necessary along with frequent updates of sequence data. Methods to overcome these challenges are presented in REF Chapter XYZ,.


\subsubsection{The Impact of Chemical Modifications on siRNA Design and Efficacy Prediction}
The incorporation of chemical modifications is essential for the development of siRNAs suitable for therapeutic applications. These modifications confer critical properties such as nuclease resistance, reduced immunogenicity, and enhanced in vivo stability. However, they also fundamentally alter the molecular mechanisms governing siRNA function, thereby invalidating many of the rules and predictive features established using unmodified or minimally modified siRNAs.

The siRNAs used in therapeutic contexts—and throughout this work—are fully chemically modified (Figure X). Common modifications include phosphorothioate (PS) linkages in the backbone, which enhance resistance to exonucleases (REF 38), and $2^\prime$-O-methyl or $2^\prime$-fluoro substitutions at the ribose, which improve stability and reduce immune activation (REFs 37, 39, 40). The inclusion of a $5^\prime$ phosphate on the guide strand promotes efficient loading into the RNA-induced silencing complex (RISC) (REF 14, SD thesis). These modifications are not merely stabilizing agents; they also reshape the thermodynamic and structural properties of the siRNA duplex and its interactions with the RISC machinery.

As a result, several canonical design principles derived from studies on unmodified siRNAs no longer apply to fully modified compounds. For instance, the importance of thermodynamic asymmetry—first described by Khvorova et al. (2003) and Schwarz et al. (2003) as a key determinant of strand selection—appears diminished in the context of fully modified siRNAs. Likewise, early work by Elbashir et al. (2001) showed that certain overhang configurations could lead to misloading of the passenger strand into RISC, resulting in off-target effects. However, such misloading is largely circumvented in therapeutic siRNAs by selectively phosphorylating only the guide strand, ensuring correct strand incorporation regardless of thermodynamic properties.

Despite their necessity, chemical modifications often lead to a general reduction in silencing efficacy (REF 44, SD thesis), likely due to disruptions in the optimal conformational dynamics required for efficient RISC loading and target recognition (REF 37, SD thesis). While various optimization strategies are under development to fine-tune the positioning of these modifications (REF 41, SD thesis), this remains a significant barrier in therapeutic siRNA design and a major limitation for existing predictive models.

Moreover, siRNA duplex architecture itself plays a role in efficacy. Asymmetric duplexes—in which the guide strand is longer than the passenger strand—have been shown to perform better than fully symmetric counterparts (REFs 35, 43, 48, SD thesis), and are used exclusively in the siRNAs designed in this study (Figure X). These structures further interact with the chemical modification landscape to impact the physical properties and efficacy of the duplex.

Taken together, these factors demonstrate that chemical modifications redefine the sequence-structure-function relationship in siRNA design. Models developed on unmodified siRNAs fail to account for these effects and generally perform poorly on fully modified compounds. Thus, predictive models for therapeutic siRNAs must be specifically trained on chemically modified sequences and must incorporate both sequence and structural features relevant to the modified duplex context. This paradigm shift underlies the central motivation for the development of new, modification-aware siRNA design algorithms.


\subsection{Where we are now and what is missing}
\subsubsection{Existing siRNA Design Software}
Efficacy prediction models alone are insufficient for designing therapeutic siRNAs. These models typically perform a single task: scoring or classifying candidate siRNA sequences. For example, some of the earliest models applied simple linear equations to score base preferences (REF Smushkovich). Importantly, the initial step of siRNA design—identifying candidate target sites—is carried out independently of these models. Additional design steps, such as filtering for off-targeting and excluding incompatible sequences, are likewise handled outside the prediction model by supplementary (often computational) processes. Collectively, these steps form the siRNA design algorithm, of which efficacy prediction is only one component (Fig X TODO: schematic of siRNA algorithm showing steps with model as a part of it). This algorithmic pipeline may be implemented manually (e.g., using spreadsheet software or text processing tools) or programmatically as part of software platforms. Computational implementations allow for greater automation, speed, and reproducibility, and reduce user error, making them preferable for contemporary siRNA design applications.

\paragraph{siRNA Algorithm Software Interfaces}
The practical utility of an siRNA design algorithm is defined not only by its predictive accuracy but also by its accessibility. A powerful model requiring specialized hardware or programming expertise may be of limited use to the broader community. Thus, tools that exist only as code repositories without user-friendly interfaces are restricted in their reach and impact. To maximize usability, siRNA design algorithms must be packaged as accessible software tools usable by anyone without requiring computer programming knowledge. These may be implemented as standalone applications, plug-ins for existing bioinformatics software, or—most commonly—as web-based applications/portals. Standalone software is often hindered by compatibility issues and maintenance burdens, while web portals provide a more flexible and maintainable solution for frequently updated tools such as siRNA design platforms.

\paragraph{Web Portals/Applications are the Future for siRNA Design}
Web portals (or web applications) allow siRNA design tools to be accessed remotely over the Internet via a web browser. This makes such tools widely accessible and easily shareable. Their web-based platform also eliminates installation barriers and system compatibility issues. Web applications are typically structured using a two-part architecture consisting of a frontend and backend. The frontend, running in the user’s browser, provides the graphical interface and interactive elements (i.e., input forms, clickable buttons, and downloadable outputs). The backend handles the core logic of the tool, including the siRNA design algorithm and efficacy prediction model, and runs on the remote server side. Effective integration of frontend and backend components is essential for creating a functional, reliable, and user-friendly platform. Developing both components requires distinct technical expertise: backend development demands knowledge of algorithm design and high-performance computing, while frontend development involves user interface design and web technologies. In academic environments, the lack of frontend development expertise often limits the production of modern, siRNA design tools as web portals. While many legacy academic web portals implementing outdated models still exist (REF TODO: list of academic siRNA design web portals), contemporary, therapeutically relevant tools are largely commercial and rely on proprietary algorithms (REF TODO: list of commercial siRNA design tools). There remains a critical need for a freely accessible, modern web portal for siRNA design based on current therapeutic advances and clinically relevant models. Such a resource would substantially advance the field by enabling broader participation in therapeutic siRNA development particularly within academic and non-commercial settings.

\subsection{Next steps for siRNA design}
Following the early days of siRNA therapeutic development, the field saw a surge of interest in efficacy prediction and machine learning approaches, especially after the release of the first large siRNA efficacy dataset (REF Huesken). This excitement led to the publication of a glut of siRNA potency prediction algorithms (REF several crummy ML algorithms using Huesken data that were done by CS people exclusively). Unfortunately, many of these models are highly theoretical/impractical (TODO: what do I mean by this?), lack essential biological context for siRNA design (TODO: give examples?), and were not experimentally validated. In addition, many exist only as code repositories, making them difficult to implement without significant computational expertise. As a result, these models offer limited value for real-world applications.
 
Even with growing awareness of the importance of chemical modifications in therapeutic siRNAs, the original Huesken dataset—composed of naked/nonmodified siRNAs—continues to be widely used. This persists despite evidence that models trained on naked siRNAs fail to generalize to chemically modified ones and vice versa (REF NAR 2018). Together, these issues underscore a critical need: the development of predictive models built on therapeutically relevant data, and stronger collaboration between machine learning experts and RNA therapeutics researchers to meaningfully advance the field.





\section{Machine Learning and Artificial Intelligence (AI) Background}

\textbf{\textit{--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---}}

Artificial intelligence (AI) refers to the broad field of computer science dedicated to creating systems that can perform tasks typically requiring human intelligence, such as reasoning, pattern recognition, decision-making, and language understanding. Within this field, machine learning (ML) is a prominent subfield focused on developing computational models that identify patterns and make predictions by learning from data. These models are built using algorithms (defined here as sets of instructions or procedures that guide how data are processed and decisions are made). In contrast to traditional rule-based algorithms, which follow fixed, explicitly programmed rules, ML algorithms adapt their internal parameters based on the data they encounter, improving performance over time without requiring manual reprogramming. The highly structured nature of nucleotide sequences, the vast scale of the transcriptome, and the need for systematic, data-driven approaches in siRNA design create an ideal landscape for computational modeling. In this context, AI, and particularly ML, offers powerful tools to accelerate the design of effective siRNAs.


\subsection{AI and Machine Learning in siRNA Design}
\subsubsection{\underline{Machine Learning}  for siRNA Efficacy Prediction}
Machine learning (ML) models have demonstrated strong predictive performance across a range of biological and computational tasks (REF), making their application to siRNA efficacy prediction a logical progression. ML-based approaches have therefore been applied extensively to siRNA design, as detailed in Chapter X. However, published models to date have faced several constraints, including underfitting, suboptimal validation strategies, and limitations in dataset size and quality. Additionally, the majority of existing models employ relatively simple algorithms, such as shallow learning methods, which may restrict their capacity to capture the complex, high-dimensional features relevant to siRNA activity (REF Huesken, others).

In addition to predicting efficacy, some ML models, particularly simpler, more interpretable ones, can offer insights into the biological mechanisms underlying their predictions by highlighting the relevance and contribution of input features. Unfortunately, deep learning models popular in the siRNA efficacy prediction field, particularly in more recent published models (REFs), typically lack this interpretability. Interpretability of simpler models can be leveraged to generate biological hypotheses and suggest potential mechanistic drivers of the observed outcomes. This process has been applied to linear siRNA design models to identify key positions and features in the targeting region relevant to silencing (REF old AK alg paper). 


\subsubsection{\underline{Feature Encoding} for encapsulating siRNA sequences}
While ML has been widely applied to improve the accuracy of siRNA efficacy prediction models, its utility extends beyond predictive modeling alone. One critical area of application is nucleotide sequence encoding, the process by which raw nucleotide sequences are transformed into numerical formats interpretable by computational algorithms. Since computers cannot directly interpret nucleotide sequences, effective feature encoding (also known as sequence embedding) is essential for proper interpretation by the model. Recent advances in sequence encoding increasingly rely on ML, particularly deep learning techniques, which have great potential to improve modeling through increased information encapsulation. Unfortunately, application of these methods in existing siRNA design models has been limited. In fact, no such published models for siRNA design exist that employ advanced sequence feature embedding methods. In our own work we show one can substantially improve both the predictive performance and computational efficiency of siRNA design algorithms. These innovations are discussed in greater detail in SECTION X. 

Together, the integration of AI and ML into both model development and sequence representation holds significant promise for improving siRNA design and, more broadly, for advancing RNA therapeutics and nucleic acid research.

\subsection{Overview:  Artificial Intelligence and Machine Learning Models}


While advanced machine learning models offer strong predictive capabilities, their complexity can introduce challenges in identifying modeling errors or sources of bias, particularly in the absence of transparent internal decision-making. This is especially true for deep learning approaches, where model interpretability is limited and issues such as information leakage may be difficult to detect, potentially leading to overestimated performance or unreliable conclusions. Proper implementation and validation are therefore essential to ensure model outputs reflect true predictive performance. This section outlines the key models used in this study, as well as several additional approaches relevant to siRNA design, with a focus on their structure and practical considerations. It is not intended as a comprehensive review of all ML or AI methods.

Although many machine learning models can be applied using existing software libraries, adapting these models to address biological questions often requires task-specific modifications. In such cases, custom implementation or parameter tuning may be necessary to achieve robust and efficient performance. While detailed technical descriptions are beyond the scope of this section, relevant implementation considerations are outlined in the Methods chapter (TODO: with code examples), particularly in instances where standard tools were insufficient. In this study, most modeling was conducted using widely available Python libraries, with custom code developed for specific components, including specialized sequence embedding strategies.


\textbf{\textit{--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---}}


\subsection{Supervised Learning: Classification and Regression}

Supervised learning is a machine learning paradigm in which models are trained on labeled datasets, where each input is associated with a known output, or “label” (e.g., an siRNA efficacy score). The goal is to learn a functional relationship between inputs and outputs that enables accurate prediction on previously unseen data. Labels can be either continuous variables (e.g., efficacy scores or gene expression levels), defining a regression task (Figure \ref{fig:classification vs regression}A), or discrete categories (e.g., functional vs. nonfunctional), defining a classification task (Figure \ref{fig:classification vs regression}B). Classification can be binary or multiclass, depending on the number of outcome categories. In certain applications, a classification model may be preferable, particularly when a binary output (e.g., functional vs. nonfunctional) aligns more closely with the experimental or therapeutic objective. In such cases, continuous labels can be discretized using binning or thresholding strategies. A thresholding approach applied in this work is described in detail in Chapter \ref{sec:trichotomous partitioning*}.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{BACKGROUND FIGURE classification_regression.png}
    \caption{TODO: caption - note is binary classification in B}
    \label{fig:classification vs regression}
\end{figure}

Supervised learning models are particularly effective for well-defined prediction tasks, especially when applied to structured data with informative and learnable patterns (e.g., nucleotide sequences) [REF]. A major strength of supervised learning is its ability to generalize from labeled training data to make predictions on previously unseen inputs. This property makes supervised learning well-suited to biological problems where reliable labels (such as phenotypic outcomes, binding affinities, or expression levels) can be assigned. When sufficient high-quality labeled data are available, supervised models typically achieve higher predictive accuracy than unsupervised approaches like clustering, which are not optimized for labeled outcome prediction.

The effectiveness of supervised models depends critically on the availability and quality of labeled data. In many biological domains, generating labeled datasets is costly, time-consuming, or experimentally impractical at scale. While unsupervised learning can reveal intrinsic data structure in the absence of labels, such approaches are generally exploratory and not designed for predictive tasks. For such problems more advanced methods are being developed, semi-supervised learning, a cutting edge method which incorporates both labeled and unlabeled data, offers a promising solution and is described in greater detail in Chapter \ref{sec:semi-supervised learning}.

\subsubsection{Linear Models}

Linear models are among the simplest types of predictive models. They aim to capture relationships between input features and outputs by assuming a linear relationship (i.e., where changes in input variables lead to proportional changes in the predicted output). A linear model can be expressed as a function as shown in Equation \ref{eq:linear equation} where $m$ represents the vector of learned weights, $x$ the input features, and $b$ the bias term.

\begin{equation} \label{eq:linear equation}
y=m^Tx+b
\end{equation}

In machine learning, linear regression and logistic regression are commonly used linear models. Linear regression is used to predict continuous values and can be represented as a function as shown in Equation \ref{eq:linear regression}. In this expression, $h_w(x)$ represents the predicted output, and each $w_i$ is a learned coefficient corresponding to an input feature $x_i$.

\begin{equation}\label{eq:linear regression}
h_w\left(x\right)=\ w_0+w_1x_1+\ldots{+w}_ix_i
\end{equation}

Logistic regression, despite its name, is used for classification tasks. It predicts the probability that an input belongs to a particular class by applying the logistic (sigmoid) function to a linear combination of the input features and can be expressed as the function shown in Equation \ref{eq:logistic regression}. The output of this function is a value between $0$ and $1$, which is interpreted as the probability of belonging to the positive class. Typically, outputs greater than $0.5 $ are classified as $1$ (positive), while those less than or equal to $0.5$ are classified as $0$ (negative).

\begin{equation}\label{eq:logistic regression}
h_w\left(x\right)=\ \frac{1}{1+e^{{-w}^Tx}}
\end{equation}

Both linear and logistic regression models rely on cost functions that are minimized during training to optimize the model’s performance. These cost functions are typically minimized through iterative computational methods such as gradient descent.

Linear models offer several advantages in biological applications. Their simple structure makes them easy to implement and interpret. They can be trained quickly and require minimal computational resources, making them particularly well suited for settings with limited data or computational capacity. Their transparency allows for direct interpretation of feature importance, as the learned coefficients reflect the contribution of each input variable to the predicted output. This makes them valuable tools for gaining biological insights.

In the context of siRNA design, linear models have been instrumental in identifying important sequence features, such as nucleotide position preferences. Their interpretability has enabled researchers to infer potential mechanistic drivers of siRNA activity (REF AK paper and others). In this work linear models have been applied to model siRNA-mediated RISC silencing, and is discussed in detail in Chapters \ref{sec:linear vs RF*} and \ref{sec:linear regression model‡}.

Linear models also have notable limitations. They are inherently unable to capture complex, nonlinear relationships or interactions between features. Because they assume that each input contributes independently to the output, they may overlook synergistic effects or, worse, double count overlapping contributions. Furthermore, linear models are highly sensitive to outliers, which can distort the learned relationships, a limitation that is particularly relevant for small, noisy datasets, as is often the case in biology.

Despite these limitations, linear models have played a foundational role in siRNA efficacy modeling. They remain useful for initial feature discovery and for establishing baseline performance. Nonetheless, to fully capture the intricacies of biological systems and improve predictive accuracy, more sophisticated modeling approaches, such as those based on nonlinear architectures or deep learning, are needed. These models are discussed in greater detail in the following sections.

\subsubsection{Random Forest Models}
\paragraph{Decision Trees}
Decision trees are predictive models that recursively partition the dataset based on input features to generate a series of decision rules (Figure \ref{fig:random forest}A). These models can be applied to both classification and regression tasks. For classification, the algorithm seeks to split the data in a way that maximally separates the classes (e.g., by maximizing information gain or minimizing impurity), while for regression, the objective is to minimize the variance of the target variable within each partition.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{BACKGROUND FIGURE random_forest.png}
    \caption{Enter Caption}
    \label{fig:random forest}
\end{figure}

One of the key advantages of decision trees is their interpretability. The structure of the tree provides a clear, visual representation of the decision process, which can be used to identify important features and generate insights into the underlying data patterns. However, single decision trees are prone to overfitting, especially when the tree becomes too deep or complex.



\paragraph{Random Forest}

Random forest is an ensemble learning method introduced by Leo Breiman and Adele Cutler in 2001 
\cite{breiman_random_2001}. Random forest builds upon the concept of decision trees by combining the outputs of many individual trees to produce a more robust, accurate, and generalizable model (Figure \ref{fig:random forest}B). This ensemble approach reduces overfitting and improves predictive performance compared to a single tree. The strength of the random forest lies in the diversity among its constituent trees. This is achieved through two main sources of randomness: (1) bootstrap sampling, in which each tree is trained on a randomly drawn subset of the training data with replacement [REF Breiman], and (2) feature randomness, where only a randomly selected subset of features is considered at each split within a tree [REF Ho, Amit, and Geman]. These mechanisms help ensure that the trees are decorrelated, improving the ensemble’s overall accuracy and stability. Random forests can be applied to both classification and regression tasks. For classification, the model aggregates predictions using majority voting, while for regression it uses the average of the individual tree outputs. This aggregation process contributes to the model’s robustness and resistance to overfitting.

Due to their flexibility and high performance, random forests are well-suited for biological datasets, particularly those with a large number of features and varying levels of importance. They perform well even with relatively small or noisy datasets. Importantly, random forests provide straightforward estimates of feature importance, which can be leveraged to identify biologically relevant variables. While not as inherently interpretable as linear models, random forests belong to the class of classical (i.e., shallow) learning models and can still provide mechanistic insight when paired with appropriate analysis methods. One such interpretation strategy is described in Chapters \ref{met:proxy feature extraction} and \ref{sec:comparing base weights identified by RF vs linear classification}.

Nevertheless, random forests do have limitations. Their ensemble nature can make interpretation more complex than with a single decision tree, particularly for large forests applied to high-dimensional problems. Training can also be computationally costly, especially as the dataset size or the number of trees increases. Additionally, random forests may be sensitive to noisy or sparse data, a challenge addressed in work described in Chapter \ref{sec:trichotomous partitioning*}. Despite these challenges, random forests remain among the most powerful and widely used machine learning models for predictive tasks in biology, offering a strong balance between performance, robustness, and interpretability.

\subsubsection{Deep Learning Models}
\paragraph{Neural Networks}

Artificial neural networks (ANNs) are a type of machine learning model inspired by the structure and function of the human brain. In machine learning, these models are used to automatically identify patterns in data and make predictions or decisions without being explicitly programmed for each task. The development of ANNs began in 1943, when McCulloch and Pitts proposed a simplified mathematical model of a biological neuron (Figure \ref{fig:Perceptron}A) (REF). They showed that networks of such units could perform logical operations, bridging neuroscience and computation [REF]. Building on this idea, Rosenblatt introduced the perceptron in 1958, which is the simplest type of neural network, consisting of a single computational layer (Figure \ref{fig:Perceptron}B) [REF]. To perform predictions, the perceptron processes a set of numerical inputs by multiplying each by a weight, summing the results with a bias term, and passing the total through an activation function (typically a step function) to produce a binary output.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{BACKGROUND FIGURE neuron_perceptron_ann_neural_network.png}
    \caption{TODO: Caption Figure legend Perceptron}
    \label{fig:Perceptron }
\end{figure}

The perceptron learns through an iterative process: it starts with randomly initialized weights, makes a prediction, compares it to the correct answer, and then updates the weights to reduce the prediction error. This cycle repeats until the model performs most predictions correctly. The perceptron effectively defines a linear decision boundary, a flat surface (called a hyperplane) that separates two classes. Because of this, it can only solve problems where such a boundary exists, i.e., where the data are linearly separable (REF Minsky and Papert, 1969). Despite these limitations, the perceptron introduced foundational ideas that enabled the development of deeper, more powerful neural network architectures used in modern machine learning.

\paragraph{Deep Learning}
To overcome the linear limitations of the perceptron, researchers developed multi-layer perceptrons, neural networks composed of multiple layers of interconnected "neurons" with nonlinear activation functions (Figure \ref{fig:Perceptron}C). These deeper architectures allow models to learn complex, non-linear patterns in data. However, training multi-layer networks was computationally difficult until the development of the backpropagation algorithm in the 1980s, a breakthrough that made deep learning feasible (REF Rumelhart, Hinton and Williams, 1986; REF LeCun et al., 1989).

Backpropagation works by efficiently calculating how much each weight in the network contributes to the final error. After the model makes a prediction, it compares the output to the true value to compute a loss. The algorithm then “propagates” this error backward through the network, layer by layer, adjusting each weight slightly to reduce the error. By repeating this process many times with many examples, the network gradually learns to make better predictions. This method unlocked the ability to train deep, flexible networks – what we now call deep learning (REF Geoffrey Hinton 2006).

Deep learning models have become central to many modern applications, including image recognition, natural language processing, and biological sequence modeling. Their ability to capture complex patterns makes them particularly appealing for use in RNA therapeutics. Unfortunately, deep learning comes with several limitations that hinder its applicability to siRNA design. Deep learning models typically require large, labeled datasets for effective training, resources that are scarce in the context of siRNA. They are also computationally intensive, often demanding access to high-performance computing infrastructure. In addition, the complexity of deep neural networks makes them difficult to interpret. Unlike simpler models, where parameters often have clear biological or statistical meaning, deep learning models are frequently treated as "black boxes"—capable of making accurate predictions without providing insight into the underlying decision-making process. This lack of transparency poses a significant challenge in scientific domains where interpretability and mechanistic understanding are essential.

As a result, despite their impressive predictive capabilities, deep learning models have shown limited success in siRNA efficacy prediction (REFs deep learning papers). Nonetheless, one of these models' other key advantages, the ability to automatically learn informative features from raw data, can still be leveraged for tasks beyond prediction, such as feature encoding, which is discussed in a later section.


\subsection{Semi-Supervised Learning}\label{sec:semi-supervised learning}

In biological prediction tasks such as siRNA efficacy modeling, one major challenge is the limited availability of high-quality labeled data, which constrains the performance of purely supervised learning approaches. Recently, semi-supervised learning (SSL) has emerged as a powerful strategy to overcome this limitation by combining the strengths of both supervised and unsupervised learning (REF). While supervised models rely solely on labeled data to learn predictive relationships, and unsupervised models uncover patterns in unlabeled data without predefined outcomes, SSL integrates both—leveraging the structure of the unlabeled data to enhance classification performance.

Despite its promise, the application of SSL in biology has been limited, in part due to the technical complexity and computational demands associated with its implementation (REFs). However, in the few cases where it has been successfully applied, SSL has demonstrated substantial improvements in predictive power. For example, our lab has employed semi-supervised learning to predict the effects of mutations on alternative splicing and their influence on protein-protein interactions, achieving unprecedented performance (Narykov et al., 2021; Zhao et al., 2014). 

The core idea of SSL is to refine decision boundaries by learning from both labeled and unlabeled examples (REF). In typical implementations, a model is first trained on the labeled dataset, then used to generate predictions on the unlabeled data. Data points with high-confidence predictions are assigned pseudo-labels and incorporated into the training set. This process is repeated iteratively, allowing the model to learn from a much larger dataset than would otherwise be possible (\ref{fig:Figure+ semi-supervised background}. By capturing structure present in the unlabeled data, SSL enables the model to generalize more effectively, resulting in improved classification accuracy on new, unseen inputs. Note that semi-supervised learning applications generally are limited to classification currently as its application to regression models is more challenging and more likely to propagate noise when predicting continuous labels on the unlabeled data. 

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{BACKGROUND FIGURE - Semi-supervised  schematic.png}
    \caption{TODO: legend. 
    Intensity of background shading in B corresponds to confidence of the classification model with lighter shading indicating lower confidence regions}
    \label{fig:Figure+ semi-supervised background}
\end{figure}


\subsection{Sequence Feature Encoding}\label{sec:sequence feature encoding}
Datasets used to train computational models often contain information that is not directly interpretable by a computer, for example, categorical labels or textual data. In biological contexts, this frequently includes nucleotide sequences, which must be translated into a machine-readable format, typically as numerical vectors. This transformation process is known as encoding. Encoding can be simple, for instance, assigning numeric codes to categories such as cell types (e.g., fibroblasts = 1, endothelial cells = 2, keratinocytes = 3). However, more sophisticated methods are often required to capture additional information such as relationships between features or context. In these cases, embedding techniques leveraging deep learning can provide richer representations of the input data.

All encoding methods inevitably involve some degree of information loss, and the choice of encoding strategy can significantly affect model performance. In the context of siRNA modeling, the method of sequence encoding can alter the amount of information captured from the sequence data. Simpler methods can cause a loss of information, while more advanced methods can encapsulate greater biological information and even identify relationships through patterns in the sequence data (REFS). In fact, we show in Chapter \ref{sec:nucleotide sequence encoding†} that the method employed for sequence encoding plays a significant role in determining the accuracy of siRNA efficacy prediction.


\subsubsection{One-Hot Encoding}\label{sec:one-hot encoding}

One of the simplest and most widely used encoding methods in biological data modeling is one-hot encoding, which represents categorical variables using binary vectors composed of 1’s and 0’s. In the context of nucleotide sequences, each nucleotide $(A, U, C, G)$ is assigned a unique binary vector. For example, $A = [1, 0, 0, 0]$, $U = [0, 1, 0, 0]$, and so on. When applied to a full sequence, this method results in a two-dimensional binary matrix where each row corresponds to the one-hot encoded form of a nucleotide at a specific position in the sequence. A method for one-hot encoding applying siRNA sequence data is described in Chapter \ref{met:one-hot encoding}.

One-hot encoding is straightforward to implement. However, this simplicity comes with substantial limitations. Chief among these is information loss: one-hot encoding treats each nucleotide position independently, failing to capture the contextual or sequential relationships between bases – features that are often critical in biology, such as motifs, base stacking, or structural dependencies (TODO: REFS). While it is theoretically possible to account for such relationships by expanding the encoding to include kmers or positional combinations, doing so increases the dimensionality of the data exponentially. This quickly becomes computationally intractable, especially for longer sequences or when modeling high-order interactions.

Despite its limitations, one-hot encoding has been the standard in published siRNA efficacy modeling and many other nucleic acid applications. To date, no studies applying more advanced encoding strategies to siRNA design have been published. This highlights both a limitation in the current modeling landscape and an opportunity to improve predictive performance by incorporating more sophisticated encoding techniques that better reflect biological complexity. 


\subsubsection{TODO: Deep Embedding Methods}\label{sec:deep embedding}
\paragraph{Continuous Bag-of-Words Embedding}\label{sec:cbow}
\paragraph{Skip-Gram Embedding}\label{sec:skip-gram}
\paragraph{Word2vec Embedding}\label{sec:word2vec}
\paragraph{FastText Embedding}\label{sec:fasttext}
\paragraph{Global Vector Embedding}\label{glove}




\chapter{LINEAR MODELS FOR siRNA DESIGN}
\section{‡A linear regression-based algorithm for chemically modified asymmetric siRNAs}\label{sec:linear regression model‡}

Non-modified siRNA efficacy is defined by the siRNA sequence itself. Many different mathematical models have been used to describe the relationship between siRNA sequence and efficacy, with nucleotide positional frequency being the essential parameter in all (see Introduction). Here we used per-position base preferences and linear regression to generate an siRNA prediction algorithm. This approach provided similar predictive power to other methodologies \cite{huesken_design_2005, he_predicting_2017, pan_sipred_2011} and enabled clear visualization of the key parameters contributing to the selection process.


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Nar 2018 Figure 2.png}
    \caption{\textbf{Algorithms derived from naked siRNA do not have predictive power for modified (siRNAs) and vice versa.}(\textbf{A}) The positional base preference matrix was generated from non-modified (orange) \cite{huesken_design_2005} and chemically modified (green) siRNA. Sequences were aligned based on the $5^\prime$ end of the antisense strand. Matrix weight values are color-coded by value as indicated by shaded bar below the matrices. Analyzed mRNA positions corresponding to siRNA-targeting region (shaded) are indicated at the top. Black arrow indicates the location of cleavage site between positions 10 and 11. (\textbf{B}) The ability of algorithms derived from non-modified and modified siRNA datasets to predict the efficacy of non-modified and modified siRNAs was calculated using PPP vs sensitivity plots. (\textbf{C}) The thermodynamic flexibility of the non-modified and chemically modified siRNAs was estimated by averaging GC content over a sliding window of four bases. Thermodynamic bias is indicated as the difference between the relative thermodynamic flexibility at $5^\prime$ and $3^\prime$ ends of the siRNA duplex. Chemically modified siRNAs do not display conventional thermodynamic bias.}
    \label{fig:Figure‡ 2}
\end{figure}


Figure \ref{fig:Figure‡ 2}A shows a positional base preference matrix computed using three functional cutoffs of different stringencies. Weights for each base and position were computed by comparing the per-position base frequencies of the functional and non-functional siRNA subsets (see Materials and Methods). The significance of the weight parameter with respect to siRNA functionality for each base was calculated using a one-sample t-test (see Materials and Methods), and non-significant values were substituted with zero. Positive weights indicate preferential occurrence of a base at a particular position in functional siRNAs, while negative numbers indicate preferential occurrence of a base at a particular position in non-functional siRNAs. Non-zero weights are indicated in the matrix table and color-coded to reflect their magnitude. The positional preferences appear to be mostly consistent for all three efficacy cutoffs used. The most prominent features of the matrix (with the highest or lowest weights) were observed at positions 7–15, a region that also encompasses the cleavage site (between positions 10 and 11 of the 20 base siRNA targeting region \cite{elbashir_functional_2001}). For analysis, we included additional sequences immediately adjacent to the targeting region aiming to detect their potential contribution or use as an embedded internal control. Although it is generally believed that the siRNA sequence itself is a primary determinant of siRNA efficacy, we observed several highly statistically significant base preferences outside the RISC-interacting region.

A linear regression model was generated using an algorithm that incorporates the per-position base preferences from the training dataset (see Methods). Algorithm performance on a dataset was assessed by comparing positive predictive power (PPP) to sensitivity (Figure \ref{fig:Figure‡ 2}B). PPP is calculated as a percent of correctly predicted (functional) sequences vs total predicted sequences for each computed score. Sensitivity is calculated as a percent of functional sequences selected versus total functional sequences present in the dataset for each computed score. For comparison, the results are also displayed as Receiver Operating Characteristic (ROC) curves and presented in Supplemental Figure‡ S2.

The $<24\%$ cutoff-based matrix was selected for further evaluation because it shows $\sim85\%$ accuracy with $40\%$ sensitivity. The Pearson correlation between the algorithm score value derived using the selected matrix and target gene expression was 0.55 on the training dataset. As a control, we generated regression models based on an equal number of randomly selected sequences distributed in similarly sized groups. The control showed no predictive power (see Materials and Methods). Thus, the linear regression of per-position base preferences adequately identifies active and inactive siRNA sequences. Figure \ref{fig:Figure‡ 2}C shows the efficacy of siRNAs predicted to be functional based on the linear regression model.

 
\section{‡Validation of modified siRNA algorithm through performance on independent datasets}

To validate the developed algorithm, we used two independent datasets generated using the same chemical scaffold as described in Figure \ref{fig:Figure* 1}B. The first dataset comprises 50 sequences targeting five genes (10 siRNAs per gene), for which efficacy was measured using qPCR in several cell lines (see Materials and Methods). The second dataset was previously published and includes 94 siRNAs targeting Huntington, for which siRNA efficacy was measured using a QuantiGene Assay \cite{alterman_hydrophobically_2015}. Our algorithm effectively predicted siRNA activity with approximately $60\%$ predictive power at $25\%$ sensitivity (Figure \ref{fig:Figure‡ 3}A and B). Construction of the validation dataset was fully independent from that of the training dataset. siRNA efficacy was measured using direct measurement of endogenous mRNA with two technical platforms for six different genes. The predictive power was lower than shown with the training set ($60\%$ versus $80\%$), which is expected and in line with the predictive power and performance of published siRNA algorithms \cite{huesken_design_2005, he_predicting_2017, pan_sipred_2011}. This outcome confirms that a linear regression-based algorithm allows the effective scoring of siRNAs, with more than half of predicted compounds being functional.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Nar 2018 Figure 3.pdf}
    \caption{\textbf{siRNA algorithm accurately predicts efficacy using two independent datasets.} The siRNA (24\%/NF) algorithm was applied to predict the efficacy of (\textbf{A}) 50 siRNAs targeting five genes (qPCR, siRNAs inducing $\sim$<25\% target gene expression are defined as functional). siRNA algorithm predicts efficacy with $\sim$60\% accuracy at $\sim$30\% sensitivity. (\textbf{B}) 94 siRNAs targeting the huntington gene (QuantiGene (34), siRNAs inducing $\sim$<25\% target gene expression are defined as functional). siRNA algorithm predicts efficacy with $\sim$80\% accuracy at $\sim$25\% sensitivity. Black line shows performance of the control algorithm (see Methods). 
}
    \label{fig:Figure‡ 3}
\end{figure}

\section{‡Non-modified siRNA-based algorithm has no predictive power for heavily modified siRNAs}

One of the major determinants of unmodified siRNA efficacy is the thermodynamic bias defining the nature of the strand entering the RISC \cite{khvorova_functional_2003, matranga_passenger-strand_2005}. The asymmetric nature of siRNA, in combination with chemical modifications, effectively precludes the sense strand from RISC entry and, theoretically, should eliminate the effect of this parameter. Thus, position-based algorithms developed for the prediction of non-modified siRNA efficacy might not be suitable for prediction with heavily modified siRNAs. To test this hypothesis, we generated a positional scoring matrix using the same methodology for a dataset of 2384 siRNAs from Huesken et al. \cite{huesken_design_2005} (Supplemental Figure‡ S1B and S1C) and compared it to the siRNA positional matrix. For this comparison, the analysis was restricted to the 20-base targeting region alone, as no flanking regions were included in the reporter construct in the Huesken et al. dataset. Figure \ref{fig:Figure‡ 4}A shows that base-preference matrices for non-modified and modified siRNAs differ substantially. As expected, the most prominent positional base preferences observed in the non-modified siRNA dataset are related to the introduction of a thermodynamic bias, with a strong preference toward A and U at the positions corresponding to the $5^\prime$ end of the antisense strand. These features were completely lacking in the siRNA matrix (Figure \ref{fig:Figure‡ 4}B). At the same time, certain nucleotide preferences observed around the cleavage site (positions 7, 8 and 11) were similar between the datasets, possibly reflecting the general nucleotide preferences imposed by the RISC complex and potentially related to dissociation of the product upon cleavage \cite{matranga_passenger-strand_2005, zamore_rnai_2000}. No other significant resemblances were observed.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Nar 2018 Figure 4.pdf}
    \caption{\textbf{Algorithms derived from naked siRNA do not have predictive power for modified (siRNAs) and vice versa.} (\textbf{A}) The positional base preference matrix was generated from non-modified (orange) \cite{huesken_design_2005} and chemically modified (green) siRNA. Sequences were aligned based on the $5^\prime$ end of the antisense strand. Matrix weight values are color-coded by value as indicated by shaded bar below the matrices. Analyzed mRNA positions corresponding to siRNA-targeting region (shaded) are indicated at the top. Black arrow indicates the location of cleavage site between positions 10 and 11. (\textbf{B}) The ability of algorithms derived from non-modified and modified siRNA datasets to predict the efficacy of non-modified and modified siRNAs was calculated using PPP vs sensitivity plots. (\textbf{C}) The thermodynamic flexibility of the non-modified and chemically modified siRNAs was estimated by averaging GC content over a sliding window of four bases. Thermodynamic bias is indicated as the difference between the relative thermodynamic flexibility at $5^\prime$ and $3^\prime$ ends of the siRNA duplex. Chemically modified siRNAs do not display conventional thermodynamic bias.}
    \label{fig:Figure‡ 4}
\end{figure}

Considering these differences, it is not surprising that the linear regression-based algorithm derived from non-modified siRNAs adequately described itself but failed to predict the efficacy of the modified siRNAs dataset and vice versa (Figure \ref{fig:Figure‡ 4}C). Consequently, unmodified siRNA selection algorithms had no predictive power for the selection of heavily chemically modified siRNA compounds.

\section{‡Regions neighboring the siRNA-targeting site contribute to efficacy}

The positional base preference matrix (Figure \ref{fig:Figure‡ 2}A) contained several strong determinants located outside of the 20-base targeting region. Previously, the mRNA secondary structure around the siRNA targeting site has been proposed as important for siRNA activity \cite{gredell_impact_2008, liu_effect_2013, tafer_impact_2008}. The propensity of RNA to form secondary structures is mostly defined by local GC content. Figure \ref{fig:Figure‡ 5}A shows calculated AU preferences for the siRNA dataset, including regions flanking the siRNA-targeting region. The level of background noise is visualized by grey areas, corresponding to the $80\%$  confidence interval derived from AU background simulation (see Methods). Individually, there are several positions displaying strong AU preference in the RISC-targeting region at positions 6, 7, 8, and 14. In addition, several positions outside the RISC-binding site, specifically on the $3^\prime$ end, display a preference for AU bases. Figure \ref{fig:Figure‡ 5}B shows an analysis of the local thermodynamic flexibility of the siRNA-targeting region along with the flanking regions. It is clear that high AU content $3^\prime$ to the targeting site is one of the most significant contributors to siRNA functional activity, since AU preference in this region is more pronounced than in the siRNA-targeting region itself. The thermodynamic flexibility (measured as AU preference \cite{khvorova_functional_2003}) $5^\prime$ of the targeting site reaches statistical significance above the background but is less distinct.
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Nar 2018 Figure 5.pdf}
    \caption{\textbf{mRNA local thermodynamic flexibility in the $3^\prime$ region outside the siRNA-targeting site contributes to siRNA efficacy.} (\textbf{A}) The frequency of AU at each position (black bars) in the siRNA-targeting region and surrounding $5^\prime$ and $3^\prime$ regions was computed by subtracting the frequency of AU in non-functional siRNAs from that in functional (< 24\% mRNA expression remaining) siRNAs. The background (grey area) was simulated using AU frequency in the randomly distributed training dataset of 356 siRNAs. The 80\% confidence interval of the simulated background is shown. Analyzed mRNA positions are indicated at the top along with corresponding siRNA-targeting region (shaded area; positions 1-20). The location of cleavage site between positions 10 and 11 is indicated with a black arrow. (\textbf{B}) The frequency of AU at each position was averaged over a four-base region (black line). The average AU frequency was computed over each region (grey dotted line). The background (grey solid line) was averaged over a four-base region.}
    \label{fig:Figure‡ 5}
\end{figure}




\chapter{SUPERVISED MACHINE LEARNING MODELS FOR siRNA EFFICACY PREDICTION}
\section{Trichotomous partitioning method for fitting machine learning models to limited datasets}\label{sec:trichotomous partitioning*}
\subsection{*Reporter-derived partially chemically modified siRNA efficacy dataset and two-threshold class annotation}
A chemically modified siRNA efficacy dataset consisting of 356 target sequences was used for ML model training\cite{shmushkovich_functional_2018}. The dataset comprises compounds targeting 17 genes, with an average of 15 siRNAs per gene. Sequences were designed with minimal constraints, mostly limited to favoring low GC content. All siRNAs were designed with the same asymmetrical chemical modification pattern (Figure \ref{fig:Figure* 1}B), to enhance cellular uptake and stability, which enhances potency \cite{layzer_vivo_2004, czauderna_structural_2003, lorenz_steroid_2004, allerson_fully_2005,choung_chemical_2006, jackson_position-specific_2006}. The asymmetrical pattern consists of a 15 nt sense and 20 nt antisense strand. On the sense strand all pyrimidines were $2^\prime$-O-methyl modified and the first two $3^\prime$ terminal linkages were phosphorothioated. On the antisense strand all pyrimidines were $2^\prime$-fluoro modified, the first six $3^\prime$ terminal linkages were phosphorothioated, and the first base from the $5^\prime$ end was fixed to a $2^\prime$-O-methyl uridine. To remove unmodified ribose stretches, purine modifications were added to both sense and antisense strands. The asymmetric structure and $3^\prime$ modifications on the sense strand ensure proper strand loading into RISC \cite{jackson_position-specific_2006}. Conjugation of cholesterol to the $3^\prime$ end of the sense strand enhances delivery of these siRNAs into cells \cite{ly_visualization_2017}. There are no other uniform (same assay, experimental set up and modification pattern), diverse (different genes) modified siRNA datasets publicly available for analysis, but the intention of the presented framework is applicability to any future datasets.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Figure 1 MTNA 2023.png}
    \caption{\textbf{Sequence data used in models and scoring scheme derived from asymmetric, chemically modified siRNAs. }(\textbf{A}) A 20 nt siRNA, when incorporated into the RNA-induced silencing complex (RISC), binds target mRNA via complementary base pairing. The siRNA guide strand positions are numbered (g1-g20). The 20 nt Target Site used for training siRNA design models is indicated and target positions are numbered (t1-t20). The sequence of this region is used to train all models. Arrow indicates location of mRNA cleavage by the RISC between positions t10 and t11. (\textbf{B}) Chemical scaffold of asymmetric siRNAs evaluated previously by Shmushkovich et al., 2018 \cite{shmushkovich_functional_2018} of 15 nt sense and 20 nt antisense strands.10 Cholesterol was conjugated to the $3^\prime$ end of the sense strand. First two $3^\prime$ terminal sense strand linkages were phosphorothioated. All sense strand pyrimidines were $2^\prime$-O-methyl modified. First six $3^\prime$ terminal antisense strand linkages were phosphorothioated. All antisense strand pyrimidines were $2^\prime$-fluoro modified. First antisense base from the $5^\prime$ end was fixed to $2^\prime$-O-methyl uridine.
}
    \label{fig:Figure* 1}
\end{figure}

 This chemical modification pattern has a profound impact on siRNA efficacy as the functional asymmetry required for proper strand loading is introduced through these modifications rather than sequence. In most existing siRNA efficacy algorithms, thermodynamic bias is a primary predictor and thus these algorithms are not predictive on modified siRNA, \cite{reynolds_rational_2004,ichihara_thermodynamic_2007,lu_efficient_2008,shabalina_computational_2006} which we have confirmed previously \cite{hassler_comparison_2018}.

 The 20 nt target site sequence for each siRNA was used as a training set for the supervised machine learning model. Base weights at each position of a target site (Figure \ref{fig:Figure* 1}A) were used as features—4 bases × 20 nt positions = 80 position-base features—to encode representation of each data point (see Methods for feature parametrization). Including other features of siRNA targeting (\textit{i.e.,} target mRNA structure, target abundance, mRNA sequence flanking the target site) could potentially improve model performance, however for simplicity, we focus on target site sequence as it is a key predictor of siRNA efficacy. Importantly, modified siRNAs, being highly structured small sequences, are not impacted by steric effects particularly in the context of identical modification patterns as is the case in the dataset used here \cite{iribe_chemical_2017,somoza_steric_2008}.

 siRNA efficacy was determined by a dual Luciferase reporter assay,\cite{shmushkovich_functional_2018} and defined as reporter expression in cells treated with siRNA as a percent of reporter expression in untreated cells. siRNA efficacies ranged from 4\% to 120\% reporter expression, with a mean and median of 44\% and 40\%, respectively (Figure \ref{fig:Figure* 2}A). The Luciferase reporter allows unification of the siRNA dataset by using a single experimental measure of efficacy. The average percent error was 3\% and individual siRNA efficacy values varied up to 16\% (Figure \ref{fig:Figure* 2}A).

 \begin{figure}
     \centering
     \includegraphics[width=1\linewidth]{Figure 2 MTNA 2023.png}
     \caption{\textbf{Noisy data and intermediate values challenge siRNA classification. }(\textbf{A}) Gene silencing efficacy for 356 chemically modified siRNAs evaluated previously by Shmushkovich \textit{et al.,} 2018 targeting 17 different genes ($\sim$15 siRNAs/gene) in HeLa cells using a dual Luciferase assay normalized to nontreated cells \cite{shmushkovich_functional_2018}. Each bar represents efficacy of a single siRNA sequence averaged over three independent measurements with error bars depicting the standard deviation. Box and whisker plot depicts distribution of siRNA efficacies across the entire dataset. (\textbf{B, C}) Data in panel A classified as effective (yellow), ineffective (blue), or undefined (grey) by the thresholds indicated (dark blue dotted lines; threshold reporter expression \% indicated at top). Number of siRNAs in each class indicated in parentheses. Inset shows regions around thresholds in greater detail. Shaded maroon boxes indicate regions with overlapping noise in the effective and ineffective classes (from maximal standard deviation value in the effective class to minimal standard deviation value in the ineffective class). Maroon bars indicate regions without overlap between effective and ineffective classes. (\textbf{D}) Data in panel A with all nine evenly spaced thresholds used in evaluation (dark blue dotted lines; threshold reporter expression remaining \% indicated at top). Spans between thresholds defined 35-36 siRNAs. Threshold pairs contained all possible combinations of nonoverlapping effective/ineffective thresholds, resulting in 45 possible combinations. Effective classes contained all siRNA sequences less than or equal to the threshold. Ineffective classes contained all siRNA sequences greater than the threshold. 
}
     \label{fig:Figure* 2}
 \end{figure}


 Consistent with other siRNA efficacy datasets, distribution of the data did not provide a clear threshold for classification (Figure \ref{fig:Figure* 2}A). A biologically reasonable threshold of 25\% reporter expression (Figure \ref{fig:Figure* 2}B) would define 94 effective siRNAs. However, data points at both sides of the threshold have large overlap in error bars (inset, Figure \ref{fig:Figure* 2}B). This noise makes data points around the threshold indistinguishable – a point directly to the right of the threshold is no different from a point to the left of it. Thus, this classification will result in a subset of sequences with biologically equivalent efficacies distributed to different classes. 

 To overcome this issue, we applied a non-conventional trichotomous grouping method that uses two independently selected thresholds, one defined effective siRNAs ($h_1$), the other defined ineffective siRNAs ($h_2$). siRNAs with reporter expression values less than or equal to the selected $h_1$ threshold were labeled ‘effective’, while those with values greater than the selected $h_2$ threshold were labeled ‘ineffective’. All siRNAs lying between these thresholds were classified as ‘undefined’ and excluded from model development (Figure \ref{fig:Figure* 2}C). This thresholding scheme results in two clearly distinct groups with no “noise overlap” (inset, Figure \ref{fig:Figure* 2}C).  

 The trichotomous partitioning method has been applied previously,\cite{shmushkovich_functional_2018} however the systematic evaluation of differing thresholds and their impact on model performance has not been performed. To optimize determination of effective and ineffective siRNA threshold values, different pairs of $h_1$ and $h_2$ efficacy thresholds were considered for testing from a range of nine equally distributed reporter expressions ranging from 15\% to 82\% (Figure \ref{fig:Figure* 2}D). All permutations of effective and ineffective threshold pairs were systematically evaluated with the constraint that $h_1$ $\leq h_2$, to exclude threshold combinations that would classify the same siRNA(s) into both effective and ineffective classes (\textit{e.g.,} $h_1$ $\leq15\%$, $h_2$ $>15\%$ was considered but $h_1$ $\leq35\%$ and $h_2$ $>22\%$ was not). In the cases where $h_1$ = $h_2$, all siRNAs were classified as either effective or ineffective and no undefined siRNAs were classified. Thus, a total of forty-five threshold combinations were considered. The size of the dataset used for model building was affected by threshold selection: models built with the most stringent threshold ($h_1$ $\leq15\%$ and $h_2$ $>82\%$ – hereon written as 15/82) were built using data from the fewest siRNAs, while models built using identical effective and ineffective thresholds use the whole dataset (\textit{e.g.,} 15/15, 22/22, etc.).

\subsection{*Pipeline for classification model development}
We evaluated the impact of all 45 threshold combinations on model performance using the pipeline in Figure \ref{fig:Figure* 3}. For each threshold pair (Figure \ref{fig:Figure* 3}A), a supervised ML model employing random forest (RF) classification was built. RF was selected because this ML model type is known to achieve a learning plateau in the fastest way, requiring the fewest number of training examples among all nonlinear ML methods \cite{fernandez-delgado_we_2014}. RF models use decision trees to partition data by their features to classify the data. In our analysis, the RF models partition data by target site position-base features to classify siRNAs as positive (\textit{i.e., }effective) or negative (\textit{i.e., }ineffective). RF performs well on data with a large number of features, and the trees and branching structure of RF have the potential to capture complex interactions (\textit{e.g.,} sequence motifs) that a simpler linear model cannot \cite{breiman_random_2001}.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Figure 3 MTNA 2023.png}
    \caption{\textbf{Schema for training supervised machine learning model to produce efficacy prediction algorithm for a single threshold combination.} (\textbf{A}) Input siRNA sequences with experimentally determined gene silencing efficacies are classified using predefined thresholds (dark blue dotted lines) into three groups: effective (E), ineffective (I), and undefined (U). Classified data are partitioned randomly into holdout (25\% of data) and training (75\% of data) sets. (\textbf{B}) Training data are split into $K (10)$ subsets of equal size. $K^{th}$ test set consisting of 1/10\textsuperscript{th} (one subset) of the training data is held out (orange pie slice) and a model is trained on the remaining 9/10\textsuperscript{ths} (nine subsets) of the training data. Model performance is evaluated using the $K^{th}$ test set. If average performance of all $K$ models is acceptable final model building can proceed, otherwise the model must be re-trained. (\textbf{C}) Using the full training set, the final model is built, and its performance is evaluated on the holdout set. If the performance is acceptable, prediction algorithm development can proceed using the model, otherwise the model must be re-trained. (\textbf{D}) The final model is used to build an algorithm to predict gene silencing efficacies of siRNA sequences whose efficacies have not been experimentally determined. 
}
    \label{fig:Figure* 3}
\end{figure}

 For model development and independent validation, the dataset was partitioned into a training set and holdout set, consisting of 75\% and 25\% of the data, respectively (Figure \ref{fig:Figure* 3}A). These partition proportions were selected as they showed the greatest overall model performance (Figure* S1). The data were split to ensure equal distribution of effective and ineffective siRNAs (per selected threshold pair for that model) into the training and holdout sets to minimize biases and optimize model development (see Methods for assessment protocol).

 Because the training and holdout sets inherently have different characteristics, bias can be introduced into the model during partitioning. This is particularly true for small, diverse datasets, as anomalies existing in only a few data points (as few as five siRNAs) can cause a model to underperform. This bias is minimized using $K$-fold cross-validation – an iterative process in which the training set is randomly partitioned into $K$ groups of equal size, then $K$  rounds of model building are performed using $K-1$ groups in training and 1 group in testing \cite{lachenbruch_estimation_1968}. The testing group is then used for model evaluation (Figure \ref{fig:Figure* 3}B). For siRNA prediction models, $K$ was set to 10, a typical number for a dataset of this size, and the cross-validation process was repeated a total of 10 times such that each partition served as the testing group once. The average performance of the $K$ models was then analyzed (see Results section on novel scoring metric for model evaluation). Default values of the standard parameters of an RF model, depth of the tree and the number of trees, were chosen because altering these parameters did not impact model performance (data not shown). Following $K$-fold cross-validation, final model training was performed with the entire training set evaluated on the holdout set (Figure \ref{fig:Figure* 3}C). Because the holdout set was not involved in $K$-fold cross-validation, model performance on this set is a strong indicator of model generalization (\textit{i.e., }performance on future unseen data). The final model is then used to build an algorithm to predict effective and ineffective siRNAs (Figure \ref{fig:Figure* 3}D). 

\subsection{*Performance of RF model for siRNA prediction is highly affected by classification thresholds}
Using $AUCPR_{adj}$ (Figure \ref{fig:Figure* 4}), we found averaged $K$-fold cross-validation model performance and final model performance on the holdout dataset (Figure \ref{fig:Figure* 5} and Tables* S1 and S2) to be generally similar. There was an overall trend of higher performance for models built with the most stringent threshold pairs (small $h_1$/large $h_2$; top left curves, Figure \ref{fig:Figure* 5}), while models built with all other threshold combinations performed poorly (bottom left, top right, and center curves, Figure \ref{fig:Figure* 5}). 

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Figure 4 MTNA 2023.png}
    \caption{\textbf{Adjusted area under the precision-recall curve overcomes challenges of model evaluation.} (\textbf{A}) Precision-recall curves for two different models developed using the same threshold values. Curves depict model performance for a better performing model (orange dashed curve) and a worse performing model (green curve). Areas under the precision-recall curve ($AUCPR$) represented by shaded regions are indicated at top. Arrow identifies precision when recall equals one ($PR=1$). (\textbf{B}) Precision-recall curves of a model with no discriminatory ability, with $AUCPR$ overestimating performance (teal dashed curve), an underfit model with $AUCPR$ underestimating performance (gold line), and a top performing model (purple dashed curve). Arrows identify $PR=1$ values for the curve of the corresponding color. (\textbf{C}) Precision-recall curves for models developed with different effective thresholds: a more stringent threshold (red curve) and a more permissive threshold (blue dashed curve) resulting in curves with identical $AUCPR$s. (\textbf{D}) Same data as in (\textbf{C}) depicting adjusted $AUCPR$ ($AUCPR_{adj}$) (red and blue shaded regions) derivation by subtracting the area defined by the $PR=1$ (red/white and blue/white striped regions) from the corresponding curve’s (red or blue) $AUCPR$. General formula for computing $AUCPR_{adj}$ is described (yellow box). Detailed $AUCPR_{adj}$ derivations for the blue and red curves provided (middle). Color bar represents the scheme used throughout this manuscript for color-coding curves by $AUCPR_{adj}$ values normalized between 0 and 100. (\textbf{E}, \textbf{F}, \textbf{G}) Same curves as in A, B, C, respectively, colored by normalized $AUCPR_{adj}$.}
    \label{fig:Figure* 4}
\end{figure}

 Top performing models – defined by a high $AUCPR_{adj}$ – utilized threshold pairs that 1) reflect biologically reasonable definitions of siRNA efficacy (<30\% reporter expression) and 2) exclude moderate-efficacy siRNA, which might be misclassified and introduce noise. The resulting models have the greatest power to distinguish effective and ineffective siRNAs, but come at the cost of excluding a larger amount of data from training. Note the term “top performing” is used here as a comparison to other models evaluated in this study only. We seek in this study to demonstrate the utility trichotomous partitioning method and present it within a simplified framework, however further parameter tuning is likely to produce models with greater predictive power. We do not intend to indicate these models outperform existing, highly tuned, siRNA prediction models.

 
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Figure 5 MTNA 2023.png}
    \caption{\textbf{Model performance per classification threshold. }Precision-recall curves depicting model performance during evaluation on the holdout set (solid lines) and $K$-fold cross-validation (dotted lines). For holdout set evaluation, random forest classifiers were trained on entire training set and evaluated on holdout set. For $K$-fold cross-validation (with $K=10$), random forest classifiers were trained on 9/10\textsuperscript{th} training subsets and evaluated on corresponding 1/10\textsuperscript{th} test subsets and precision-recall curve values were averaged over 10 rounds of model building. Each plot represents performance of models trained using different effective and ineffective siRNA threshold pairs. One can use the adjusted area under the precision-recall curve ($AUCPR_{adj}$) to evaluate model performance. Curves are colored by $AUCPR_{adj}$, which were normalized within each evaluation step (either $K$-fold cross-validation or holdout set evaluation). Color bar depicts performance by normalized $AUCPR_{adj}$. $AUCPR_{adj}$ values indicated at bottom right of each curve $K$-fold cross-validation (red) or holdout set evaluation (black). Bar plots at top and left depict all siRNA target expression data (as in \ref{fig:Figure* 2}D) colored by effective (top) or ineffective (left) thresholds. Precision-recall curves are aligned to these bar plots to indicate the effective and ineffective thresholds used for training of the corresponding curve’s model. Thresholds are inclusive of all data with expression values less than (for effective thresholds) or greater than (for ineffective thresholds) the threshold expression percentage. Data used to compute normalized $AUCPR_{adj}$ values in Tables* S1 and S2.
}
    \label{fig:Figure* 5}
\end{figure}

 In $K$-fold cross-validation, the top performing threshold pairs ($h_1$/$h_2$) were 15/65, 15/53, 22/82, and 22/53 (Figure \ref{fig:Figure* 5}). The most stringent threshold pair, 15/82, did not perform well, likely due to the smaller dataset used. In final model evaluation, $AUCPR_{adj}$  identified 15/82, 15/65, 15/40, 22/65, 22/53, and 22/46 as top performing threshold pairs (Figure \ref{fig:Figure* 5}). The strong performance of the 15/40 threshold pair, which allows greater inclusion of moderate-efficacy siRNAs, was driven by the identification of true negatives (contingency table, Figure* S3). In fact, the model did not identify any true positives, suggesting the model would not likely perform well for effective siRNA identification. This exemplifies the challenges of model building with a limited dataset, where thresholding can further reduce the evaluation set size (to as few as 17 siRNAs in this assessment), and demonstrates that no single evaluation metric alone is ideal. Considering multiple metrics – in this case $AUCPR_{adj}$ and the contingency table – is critical for evaluating final model performance. 

 In evaluating contingency tables, the application of the model is important to consider. The threshold pair 22/53 produced a top performing model based on $AUCPR_{adj}$, however the resulting contingency tables show only two siRNAs identified as true positives along with many false negatives (Figure* S3). Critically, however, is that no false positives were identified by this model, which in the context of siRNA design are highly costly. The large number of false negatives are acceptable because for siRNA efficacy prediction, the model need not excel at identification of negative values. These results further highlight the challenge presented in evaluating models with such a small dataset and further highlight the value of considering multiple metrics (in this case including $AUCPR_{adj}$) in model evaluation.

 $AUCPR_{adj}$ successfully identified three categories of poor-performing models. The first category of models utilized moderately effective and ineffective threshold pairs (curves in second through forth rows from the top and second through forth columns from the left, Figure \ref{fig:Figure* 5}). Corresponding contingency tables (center tables, Figures* S2 and S3) show the models falsely classify many ineffective siRNAs as effective. This poor performance is likely due to the models including moderate-efficacy siRNAs. The two remaining categories were highly underfit models or those with no discriminatory ability. Underfit models are identified by their low $AUCPR$ and $P_{R=1}$, and were built from threshold pairs producing a larger number of ineffective siRNAs ($h_2$= 29\%, 22\%, or 15\%) (bottom left curves, Figure \ref{fig:Figure* 5}). Models with no discriminatory ability are built from threshold pairs classifying the majority of siRNAs as effective ($h_1$ = 53\%, 65\%, or 82\%) (top right curves, Figure \ref{fig:Figure* 5}). Such models have a high $AUCPR$ with a high $P_{R=1}$. This poor performance is likely due to overly permissive effective thresholds mislabeling ineffective siRNAs as effective.

 Some threshold pairs produced models that performed notably worse on the holdout set than they did in cross-validation (22/65, 15/46, 22/46, and 15/40) (Figure \ref{fig:Figure* 5}). This is likely due to inherent differences between the holdout and training datasets that were not captured in the model during training, and reflects the small dataset size. These discrepancies are not due to unequal representation of effective and ineffective siRNAs in the holdout versus test groups in $K$-fold cross-validation (Figures* S2 and S3); equal representation of effective and ineffective siRNAs was maintained during partitioning of training and holdout sets as well as during $K$-fold partitioning (see Methods). 

 Evaluating model performance using ROC curves (and their corresponding $AUC$s) did not provide a clear top performing model ($AUC > 0.85$) (Figures* S4 and S5), \cite{davis_relationship_2006} exemplifying the importance of selecting the proper metric for model evaluation. This is particularly striking when considering final model evaluations, where the most permissive ineffective siRNA thresholds showed some of the greatest $AUC$s (bottom left curves, Figure* S5) despite being underfit, as determined by their contingency tables.

\subsection{*RF model outperforms linear classification model built from the same dataset}\label{sec:linear vs RF*}
We next compared the performance of RF with a linear model to classify siRNA efficacy in this dataset (Figure \ref{fig:Figure* 6}). For this comparison, we selected a published linear classification method that leverages an \textit{ad-hoc }function and utilizes the threshold pairs \cite{shmushkovich_functional_2018}. We selected this linear method because it was previously applied to the siRNA dataset used here \cite{shmushkovich_functional_2018}. As with the RF model, there was a general trend in higher performance of linear models built with the most stringent threshold pairs (top left curves boxed in pink, Figure \ref{fig:Figure* 6}). Overall, RF performed better than linear, as determined by higher mean and median $AUCPR$s for top performing models (box plot, Figure \ref{fig:Figure* 6}). While overall performance of the linear model was significantly worse than RF, it showed some predictive power with the same top performing thresholds, indicating that elimination of moderate efficacy siRNAs from model development is beneficial for both simple linear models and more sophisticated ML models.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Figure 6 MTNA 2023.png}
    \caption{\textbf{Comparing random forest and linear models. }Precision-recall curves for random forest classifiers (purple curves) and linear classifiers (teal curves) trained on entire training set and evaluated on holdout set. Each pair of overlaid curves represent performances of models trained using a different effective and ineffective siRNA threshold pair. Bar plots at top and left depict all siRNA target expression data (as in Figure \ref{fig:Figure* 2}D) colored by effective (top) or ineffective (left) thresholds. Precision-recall curves are aligned to these bar plots to indicate the effective and ineffective thresholds used for training of the corresponding curve’s model. Thresholds are inclusive of all data with expression values less than (for effective thresholds) or greater than (for ineffective thresholds) the threshold expression percentage. One can use the area under the precision-recall curve ($AUCPR$) to evaluate model performance; $AUCPR$s are indicated in bottom right corner of each plot and color-coded by model type. Box plots on right depict the distribution of $AUCPR$s for models built with the most stringent thresholds (boxed in pink).
}
    \label{fig:Figure* 6}
\end{figure}

\subsection{*Comparing base weights identified by RF vs linear classification models}\label{sec:comparing base weights identified by RF vs linear classification}
We then analyzed the extracted base weight matrix from linear and RF models built using the same top performing threshold pair (Figure \ref{fig:Figure* 7}). Overall trends in base weights were similar with similar AU/GC weights and identical AU/GC favorability (directionality) at 14 positions (Figure \ref{fig:Figure* 8}). RF models produced greater resolution (\textit{i.e.,} the differences between maximal and minimal base importances are greater, enabling greater discrimination), likely explaining better model performance. For both models, there was a trend of no base importance near the seed (guide and target strand mRNA positions 2-5 hereon written as: g2-g5/t2-t5), followed by a region of flexibility (g6-g7/t6-t7), then high affinity near the cleavage site (g8-g11/t8-t11), and high flexibility in the tail (g13-g17/t13- t17). Weaker base importance in the $3^\prime$ region (positions t2-t5), which corresponds to the $5^\prime$ end of the siRNA seed, likely reflects the need for sequence variability to accommodate a wide range of siRNAs, as this region determines siRNA specificity. The lack of specificity here also highlights the flexibility of the model to accommodate a large range of mRNA targets. There is no importance of any base at position t11. Base pairing in this central region is known to be important for effective cleavage,\cite{ameres_molecular_2007, haley_kinetic_2004, wee_argonaute_2012}, therefore it is possible that the lack of importance at this position is necessary to accommodate different bases in different siRNAs and targets. Even a linear model developed using data from unmodified siRNAs showed low importance of any base at position t11,\cite{shmushkovich_functional_2018} suggesting the significance of this position. Absent from these extracted weights is thermodynamic asymmetry, which is critical for nonmodified siRNAs,\cite{reynolds_rational_2004, ichihara_thermodynamic_2007, lu_efficient_2008, shabalina_computational_2006} but is encapsulated in the chemical modification scaffold for the modified siRNAs used in this model. 

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Figure 7 MTNA 2023.png}
    \caption{\textbf{Target site base feature weights identified by siRNA efficacy prediction models. }(\textbf{A}) Base feature weights extracted from random forest model. Weights were extracted from the 20 nt target site sequence and are aligned with respect to the RNA-induced silencing complex (RISC) (see Figure \ref{fig:Figure* 1}A) in a matrix by nucleobase indicated in magenta along the left. Positions indicated for target (t) and guide (g) sequences. Weights are colored by value following the scale indicated. Magnitude indicates importance for the particular model, with higher magnitude weights indicating bases more important for prediction. Bases with zero weights are not important to prediction for the particular model. Direction (positive/negative) indicates favorability of a base with respect to identifying effective siRNAs for the particular model, with positive weights indicating a feature is favored in identifying effective siRNAs, and negative weights indicating disfavoring. Model developed using 22\% effective and 53\% ineffective thresholds respectively. Arrow indicates mRNA cleavage site between positions t10 and t11. (\textbf{B}) Same as A but for a linear model. Base weights were extracted by proxy (see Results and Methods).
}
    \label{fig:Figure* 7}
\end{figure}

 Thermodynamic trends are intrinsically linked to base weights \cite{reynolds_rational_2004}. To examine thermodynamic trends, the summed GC weights were subtracted from the summed AU weights at each position (Figure \ref{fig:Figure* 8}) \cite{khvorova_functional_2003}. At all but three positions (t2, t10, t16) the $AU$-$GC$ subtracted weight directionalities had the same favorability in both models. In positions of identical directionality, RF frequently had a larger magnitude and thus higher importance. Although thermodynamic asymmetry is required for siRNA efficacy,\cite{khvorova_functional_2003}. asymmetry was introduced through chemical modification and structure in this siRNA dataset; and thus, does not appear in the weight matrix as a major determinate of efficacy. Overall, base weights (and their corresponding favorabilities and importance) from both models are consistent with the current understanding of siRNA-RISC targeting recognition and cleavage for both modified and nonmodified siRNAs \cite{wee_argonaute_2012, becker_high-throughput_2019, deerberg_minimal_2013, jo_human_2015, neumeier_sirna_2021, sheu-gruttadauria_structural_2017}.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Figure 8 MTNA 2023.png}
    \caption{\textbf{Thermodynamic trends in base weights extracted from random forest and linear models. }Comparing thermodynamic trends approximated by subtracting summed GC weights from summed AU weights extracted from the random forest (purple) and linear (teal) models. Weights were extracted from the 20 nt target site sequence and are aligned with respect to the RNA-induced silencing complex (RISC) (see Figure \ref{fig:Figure* 1}A). Positions in sequences indicated for mRNA target (t) and siRNA guide (g) strands. Base weights were extracted from their respective models using proxy method (see Results and Methods). Base weight positions are indicated with respect to the position in 20 nt target mRNA sequence (x-axis). Arrows indicate mRNA cleavage site between positions t10 and t11. Both linear and random forest models from which weights were derived were developed using an effective threshold of 22\% and an ineffective threshold of 53\%. See also Figure* S6.
}
    \label{fig:Figure* 8}
\end{figure}

\subsection{*Evaluation of models on randomized siRNA dataset}
To further assess the accuracy of our model, we evaluated its performance on randomly designed siRNAs by shuffling the siRNA efficacies with respect to their sequences in the holdout set. The resulting model performance of these randomized siRNAs is poor (Figure* S8), indicating that model fitting is in fact occurring to relevant sequence information rather than random noise inherently present in such a small dataset.

\subsection{*Evaluation of model building pipeline on external datasets}
To determine if our pipeline can indeed be applied more widely, we applied it on two external sets of nonmodified siRNAs. The first dataset (hereon referred to as Set 1) was evaluated previously by Reynolds \textit{et al.,} and consisted of 240 siRNA sequences and their corresponding target gene expressions remaining (as a percentage of a control) evaluated in HEK293 cells by either branched-DNA assay or Luciferase reporter assay (Figure* S9A) \cite{reynolds_rational_2004}. The second dataset (hereon referred to as Set 2) was evaluated previously by Huesken \textit{et al.} and consisted of 2,431 siRNA sequences and their corresponding normalized inhibitory activities evaluated in HeLa cells using a hypoxia-response element-Luciferase reporter assay (Figure* S9B) \cite{huesken_design_2005}.

 Set 2 consisted of approximately seven-fold more (2,431 nonmodified siRNAs) than the data on which the pipeline was developed (356 modified siRNAs). Evaluating our pipeline on such a large dataset may unfairly overestimate our pipeline’s potential. Thus, in addition to applying the pipeline to the full Set 2 dataset, we also applied the pipeline to a downsized dataset of 350 randomly selected (see Methods) sequences (hereon referred to as Set 2 Downsized, Figure* S9C).

 The trichotomous grouping method and pipeline for classification model development (Figure \ref{fig:Figure* 3}) were applied to all three datasets (Set 1, Set 2, Set 2 Downsized) following the identical protocol and parameters applied for modified siRNAs (see Methods) to produce RF classification models. Effective/ineffective thresholds were selected independently for each dataset by evenly distributing the data by efficacy into ten groups. The equally distributed efficacy thresholds for Set 2 Downsized differed slightly to those of the full-size Set 2 due to small changes in the distribution of the randomly selected downsized dataset (Figure* S9). Model performances were assessed at different threshold combinations by plotting precision-recall curves (Figures* S10, S11, and S12). 

 Set 2 was the largest and thus, as expected, models built from it showed the strongest performance when evaluated on the holdout set (Figure* S11). On the two smaller datasets, strong model performances on the holdout sets were seen for several threshold pairs including 10/49 and 10/61 effective/ineffective for Set 1 (Figure* S10), and 15/42 and 7/42 for Set 2 Downsized (Figure* S12). 

 Compared to the dataset on which the model building pipeline was developed, Set 2 had a greater representation of effective siRNAs, causing threshold distributions to skew lower (compare Figure \ref{fig:Figure* 2}A with S9B, and bar plots in Figure \ref{fig:Figure* 5} with S11). Despite this difference, predictive models were achieved, exemplifying the applicability of this framework to datasets that are significantly different in both content and distribution. Even within Set 2 Downsized this shifted distribution of efficacies remained and predictive models were able to be developed using the same pipeline (Figure* S9). 

 All three external datasets produced a pattern of model performance similar to that seen with models built with modified siRNAs (Figure \ref{fig:Figure* 5}) in which models built with the second to third lowest effective thresholds first and third highest ineffective thresholds produced models with strong performance. This indicates robustness in the thresholding method as thresholds were selected independently for each dataset by evenly distributing the data by efficacy into ten groups. This demonstrates the applicability of the trichotomous data partitioning method and model building pipeline presented in this manuscript to other datasets of a similar scale to enable development of predictive ML models from limited datasets. 

 The features for a top performing model from each of the three external sets (built from the 10/61, 14/49, 15/42 effective/ineffective threshold pairs for the Set 1, Set 2, and randomly Set 2 Downsized datasets respectively) were extracted (see Methods) and the resulting base weights were visualized (Figures* S13, S14, and S15). The structure of the nonmodified siRNAs from both Sets 1 and 2 differed from the modified siRNAs, consisting of a 21 nt duplex with two deoxynucleotide overhangs on the $3^\prime$ terminus \cite{huesken_design_2005,reynolds_rational_2004}. The resulting difference in guide strand length is depicted in the RISC schema in Figure* S15. The models were built using the 20 nt target site, enabling direct comparisons of base weights across the models. While base weights from each model show some similarity with those extracted from the model built with modified siRNA (Figure \ref{fig:Figure* 7}), overall trends are quite different. The weights extracted from the Set 1 model show little importance in the seed region. Across all three sets there is a moderate trend of AU favoring and GC disfavoring in the $3^\prime$ region of the target site, and the opposite trend in the $5^\prime$ region. Features extracted from Set 2 and its randomly downscaled Set 2 Downsized show general trends in similarities but also differ at several positions with the features derived from the larger Set 2-produced model having a greater number of positions with high importance.
 
\subsection{*Experimental evaluation of pipeline on panel of synthesized siRNA}

To experimentally evaluate our pipeline in the context of siRNA design, we applied our top performing random forest model (built using 22\% effective and 53\% ineffective thresholds; Figure \ref{fig:Figure* 5}) to classify compounds targeting transcripts from four human genes: \textit{MAPT}, \textit{APP}, \textit{SNCA}, and \textit{BACE1}, see Methods. 

 The ten siRNAs with the highest confidence scores predicted to be effective, and the ten siRNAs with the lowest confidence scores predicted be ineffective were selected for experimental evaluation (Table* S3). siRNAs were synthesized with the twenty selected targeting region sequences, and their silencing efficacies were experimentally evaluated using a dual Luciferase reporter assay system (see Methods, Figure* S16A). Of the 10 compounds predicted to be effective 7 were truly functional. Of the 10 compounds predicted to be ineffective 8 were truly nonfunctional (Figure* S16B). These results indicate that the RF model developed using the framework presented here can be applied to successfully identify functional siRNAs. 

\section{Supervised learning models for fully modified siRNAs evaluated in native context}


\subsection{†Developing and validation of fully chemically modified siRNA endogenous efficacy dataset}

Full chemical stabilization is essential for conjugate mediated silencing. Evaluating therapeutic fully modified siRNA efficacy against endogenous transcript targets is an experimentally complex task that is time consuming and costly. Reporter-based assays are often used as a proxy to define siRNA functional activity; however we have recently demonstrated that only a fraction of siRNAs active in reporter assays are effective in a native mRNA context (Davis et al., in review with NAR). This is likely due to the combined influence of RISC interactions, target size, and specific mRNA features contributing to observed efficacy. Full chemical stabilization is essential for conjugate-mediated delivery, and most clinically advanced siRNAs are heavily modified. Since chemical modifications significantly impact RISC interactions, data and algorithms generated using non-modified siRNA datasets have limited predictive power for fully modified siRNAs \cite{shmushkovich_functional_2018}.Thus, a dataset of fully chemically modified siRNAs with endogenous efficacy is necessary to train algorithms that account for both RISC and target-specific features. Such a dataset does not currently exist publicly. 

As a part of a decade-long study of therapeutic siRNA functionality we have curated a large dataset of fully therapeutically chemically modified (Figure \ref{fig:Figure† 1}A) siRNA silencing efficiencies evaluated in triplicate in a native context using QuantiGene assay (see methods). The dataset consists of 2475 human and 1752 mouse fully chemically modified siRNAs targeting 52 and 50 genes respectively (Figure \ref{fig:Figure† 1}B and Supplemental Figure† S2A). The dataset includes minimally ten ($\sim$50 on average) siRNAs per target allowing strict control for assay validation (see methods). The quality and large size of this dataset provides an opportunity to explore advanced machine learning techniques to model both RISC and target mRNA sequence features contributing to siRNA efficacy. 
All compounds were modified with the highly RISC-compatible modification pattern shown in Figure \ref{fig:Figure† 1}A. The compounds were conjugated to cholesterol and contain a five based overhang insuring efficient passive internalization in all cell types (REF chemical scaffold). We have previously demonstrated that the structure of the siRNAs (length of the overhang) has not significantly impact on measured siRNA efficacy, thus data generated with this dataset should be applicable for design of siRNA of different fully modified structural configurations (Davis et al., in review with NAR). Using a trichotomous labeling system \cite{monopoli_asymmetric_2023}, siRNAs were classified into three groups: efficient ($\leq25\%$; 782 siRNAs), inefficient ($\geq60\%$; 853 siRNAs), and undefined ($>25\%$ and $<60\%$; 840 siRNAs). The undefined group, which is excluded from the initial analysis, ensures clear resolution between active and non-active compounds \cite{monopoli_asymmetric_2023}.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{MONOPOLI 2025 - Figure 1. Data splitting, efficacy classification, and gene set distribution.png}
    \caption{\textbf{Endogenous gene knockdown efficacies of a panel of fully chemically modified siRNAs and partitioning scheme used for model building.} \textbf{A} fully modified chemical scaffold of siRNAs used for screening assays. \textbf{B} Bar plot inside circle depicts endogenous gene silencing efficacies of all 2475 fully chemically modified siRNAs targeting 52 different genes (~49 siRNAs/gene) measured in human cells using QuantiGene Singleplex assay. Each bar represents the efficacy of a single siRNA averaged over three independent measurements, with error bars indicating the standard deviation. Data are labeled for classification model building by applying two thresholds (vertical dotted lines) into three efficacy classes: efficient (yellow), inefficient (blue), and undefined (grey) with the number of siRNAs in each class indicated at the top of the plot. Within the circle, the proportions of the three labeled efficacy classes (colored as described above) in the Training (left, teal donut charts) and External (right, red pie charts) datasets following data partitioning are depicted for both data Split Randomly (navy semicircle above bar plot) and data Split by Gene (pale blue semicircle below bar plot). The outer circle plot depicts the 52 human genes targeted by the starting full dataset of 2475 fully chemically modified siRNAs, with each different colored section representing a single gene (name in black text outside circle) with arclength proportional to the number of siRNAs targeting that gene present in the starting dataset (see scalebar; top left, pink). Inner rings of the circle depict partitioning of genes into Training and External Datasets for model building described in further detail in the inset.  (\textbf{Inset}) describing inner circle plot from B. The inner circular bar plot depicts the proportion of each individual gene targeted siRNAs present in the training vs. external dataset following data Split Randomly. The innermost ring represents the resulting randomly selected dataset (External or Training) following data Split by Gene. \textbf{C} Proportion of siRNA gene silencing data from B present in the Training Dataset following random partitioning. Data are colored by class label as in B with the number of siRNAs in each class indicated in the text of the plot. \textbf{D} Proportion of siRNA gene silencing data from B present in the External Dataset following random partitioning; data are described as in C. \textbf{E} Proportion of siRNA gene silencing data from B present in the Training Dataset following partitioning by gene; data are described as in C. \textbf{F} Proportion of siRNA gene silencing data from B present in the External Dataset following partitioning by gene; data are described as in C. }
    \label{fig:Figure† 1}
\end{figure}

Target sequence and target gene expression percentages are provided in Supplemental Table† S1. Most of the targets included in the dataset are of therapeutic significance. Analysis of sequence-based similarities within the 20-nucleotide targeting regions for both human and mouse (Supplemental Figure† S1E-F) datasets and demonstrates the lack of intrinsic bias, thereby validating the dataset for model training. This highly curated fully chemically modified endogenous siRNA efficacy dataset is the first of its kind to be made publicly available. Its large size is sufficient for application of new highly predictive advanced machine learning techniques which we leverage in this study to show great success in therapeutic siRNA efficacy prediction.


\subsection{†Pipeline simulating real-world application through orthogonal dataset evaluation}

The development of a large, high-quality dataset of fully chemically modified siRNAs enabled a systematic evaluation of the impact of applying advanced machine learning methods on siRNA efficacy prediction accuracy. We first set out to systematically assess the relative importance of sequence encoding methods and model parameters on predictive performance. The general model-building pipeline is outlined in Figure \ref{fig:Figure† 2}A–D. We employed a standard stratified partitioning methodology, randomly splitting the data into a Training Dataset (75\%, $\sim$1856 siRNAs) and an External Evaluation Dataset (25\%, $\sim$619 siRNAs), while maintaining equal distribution across the three efficiency classes (efficient, non-efficient, undefined; Figures† 1D-E and 2A). The dataset includes siRNAs targeting 52 different genes. At this stage, the data was treated as a whole, with each gene’s data equally distributed between the training and external evaluation sets to minimize potential biases. In all cases, the External Dataset was held aside until final model evaluation and was never used during model training, ensuring an unbiased assessment of model performance on unseen data. K-fold Cross-Validation was employed to ensure robust performance across a wide range of data subsets, using $\sim$15\% of the data for testing in each of ten iterations, with randomized shuffling of data allocations (see Methods).

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{MONOPOLI 2025 - Figure 2. Model Training Pipeline.png}
    \caption{\textbf{Machine learning model fitting pipeline and methods for encoding target transcript sequence data.}
\textbf{A} siRNA efficacy data are classified into three efficacy groups using trichotomous thresholding method describe previously (REF). Data are randomly partitioned into a Training Dataset of $\sim75\%$ and External dataset of $\sim25\%$ such that efficient and inefficient siRNAs are distributed proportionally into the two sets based on the starting dataset proportions. All Undefined data are kept in the External Dataset. \textbf{B} The Training Dataset is further partitioned into an $\sim75\%$ Building Set (green), $\sim10\%$ Parameter Optimization (PO) Set (gold), and $\sim15\%$ Test Set (purple) with proportions of efficient and inefficient siRNAs in each set equal to that of the starting dataset. The efficacy-stratified partitioning was performed $N = 25$ times shuffling the data each time. In the final round the PO Set was including in the Building Set in preparation for Final Model building. \textbf{C} Partitions generated in B were applied for Parameter Optimization; all sequence data from the partitions are first encoded, then Building Set data are used to train a model (KSN), the PO Set data are used to evaluate the model’s performance. This process is repeated $N = 25$ times for all Parameters optimized (Kmer Size, Word Frequency, Flank Length, Window Size). Parameter values producing the top performance scores are selected. TODO: WHAT DID I DO WITH THE PURPLE TEST SET? \textbf{D} Final Model building is performed with the top performing parameters using the full $\sim75\%$ Training Dataset and evaluated on the $\sim25\%$ External Dataset (including undefined siRNAs). \textbf{E} Depiction of one-hot target sequence encoding method, which uses a matrix of 1’s and 0’s and that is then flattened by position into a vector representing the encoded sequence data. \textbf{F} Depiction of Deep Word2Vector Embedding (REF) sequence encoding method in which the sequence is broken up into segments (kmers) and then encoded using a neural network trained to predict the sequence in parts by either using a single middle kmer to predict the surrounding context kmers for Skip-Gram embedding (left) or using surrounding kmers to predict the middle kmer for Continuous Bag-of-Words (CBOW, right). The weights from the edges of trained neural network are then concatenated into a vector representing the encoded sequence data. \textbf{G} Depiction of Deep FastText Embedding  (REF) sequence encoding method in which the sequence is broken up into segments (kmers) that are further broken down into (n-grams) and then encoded using a neural network trained to predict the sequence in parts by either using a set of middle n-grams to predict the surrounding context kmers for Skip-Gram embedding (left) or using surrounding n-grams to predict the middle kmer for Continuous Bag-of-Words (CBOW, right). As in F, the weights from the edges of trained neural network are then concatenated into a vector representing the encoded sequence data. \textbf{H} Depiction of Global vector embedding (GloVe) (REF) sequence encoding method in which the sequence is broken up into segments (kmers) which are arranged in multidimensional space based on similarity of context such that more similar sequences occur more closely together in space. The kmer coordinates are then compiled into a single vector representing the encoded sequence data.}
\label{fig:Figure† 2}
\end{figure}

The Random Forest supervised learning model (see Methods), previously shown to perform well for siRNA design (REF), was used as the starting point. Models were trained on siRNA target sequence information, including regions flanking up to 100 nucleotides in both the $5^\prime$ and $3^\prime$ directions, to capture not only the sequence’s direct impact on RISC loading and target interactions but also the influence of the surrounding sequence environment (REF). Model performance was evaluated using Precision-Recall curves and the $F1$-score (see Methods Chapter \ref{met:model performance eval}), standard metrics that are particularly suitable for datasets with an imbalanced distribution of positive (efficient siRNAs) and negative (inefficient siRNAs) examples (REFS for PR curves).

\subsection{†Exploring Parameter Space to Optimize Model Performance}

We first explored whether systematic optimization of model parameters could improve performance. Supplemental Figure† SX shows the impact of modulating four key variables: flanking region size (the number of nucleotides upstream and downstream of the targeting site), k-mer size (the length of sequence fragments used as encoding units), window size (the step size between adjacent k-mers), and k-mer frequency (the minimum number of times a k-mer must appear in the dataset to be included in the embedding dictionary). For each parameter combination, the model was built 25 times using five different sequence embedding methods (see next section), resulting in the construction and evaluation of over 10,000 unique models. Figure \ref{fig:Figure† S5}A illustrates the impact of these parameters on the Word2Vec feature extraction method (see next section), which performed best in the context of fully supervised learning. We found that including flanking sequence information provided a minor but consistent improvement in model performance, with optimal gains observed when up to 20 nucleotides were added on each side of the targeting site. This supports previous findings on the influence of local sequence context on siRNA efficacy.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{MONOPOLI 2025 - Supplemental Figure 5. Parameter optimization schema and results supervised and semi-supervised models GloVe Embedding only.png}
    \caption{Summary of parameter optimization for supervised and semi-supervised learning models. A Schema describing model parameters explored in parameter optimization and their corresponding relationship to the siRNA-RISC targeting mechanism. B Box plots depicting model performance by F-score measure of supervised random forest models with the indicated parameter values (bottom of each plot). Except the indicated parameter being optimized, all parameters were held constant at: flank sequence length = 20nts, kmer size = 9nts, window size = 1nt, word frequency cutoff = 1. Parameter optimization was performed by refitting models twenty-five times shuffling the parameter optimization data set each time (see Figure \ref{fig:Figure† 2}). Median F-scores for each parameter value explored are indicated below the box in the corresponding color. Models were trained on a $75\%$ training set and evaluated on a $10\%$ parameter optimization set which were split randomly. All models applied Word2Vec Continuous Bag-of-Words embedding. Results in B were limited for comparability to C, for more complete results exploring all parameters see TODO: Figure S6. Final supervised model parameters selected are indicated by labeled red arrows. C Same as B but with semi-supervised models applying GloVe embedding with model fittings limited to fifteen rounds and with data split by gene rather than randomly.
}
    \label{fig:Figure† S5}
\end{figure}

Increasing the k-mer size led to a marked improvement in performance, with the optimal range between 7–9 nucleotides, suggesting the presence of functional sequence motifs. A window size of 1 yielded the best results; although increasing the window size reduced computational complexity, it had a significant negative impact on performance and was therefore not considered viable. K-mer frequency, a parameter known to heavily influence other sequence-based models, had no measurable effect on performance in this context; thus, a frequency threshold of 1 was selected.  (TODO: add references).



\subsection{†Nucleotide Sequence Encoding: Feature encoding methods have a profound impact on model performance}\label{sec:nucleotide sequence encoding†}


\subsubsection{†Deep learning methods for sequence feature encoding substantially boost siRNA efficacy prediction}

Sequence feature information includes nucleotide identity (A/U/C/G) and position within the target sequence and flanking region, which must be encoded (i.e., translated) into a numeric format to allow the machine learning model training software to interpret the information (REF).  One-hot encoding is the typical encoding method used in sequence information analysis (REFs). It involves representing a sequence as an array of ones and zeros defining the presence or an absence of the nucleotide in a particular position (Figure \ref{fig:Figure† 2}E). This simple method treats each base independently, and thus all contextual biological information is lost (e.g., nucleotide relationships, sequence motifs, etc.). We have previously shown that one-hot encoding produced reasonably predictive models when applied to siRNA datasets generated using reporter assays. The main difference with the endogenous dataset is the significant impact of transcript-specific information on siRNA efficacy, where only a subset of compounds active in the reporter assay also show efficacy endogenously. Interestingly, when tested on the endogenous dataset, the models performed poorly, indicating a failure to capture the complex intracellular transcript context interactions that affect siRNA activity (Figure \ref{fig:Figure† 3}B).

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{MONOPOLI 2025 - Figure 3. Precision-Recall Curves Supervised Model Performances.png}
    \caption{\textbf{Supervised learning model performance for predicting siRNA efficacy.} A Precision-recall curves depicting average performance of supervised learning models built with (teal) test and (red) external data split randomly for different sequence feature encoding methods (encoding method indicated at top of each plot). Human siRNA efficacy data used for model building described in Figure \ref{fig:Figure† 1} Curves depict model performance from curves averaged over ten rounds of model fitting with correspondingly colored shaded regions depicting confidence intervals of these averages. F-scores averaged over ten rounds of model fitting are shown in the top right corner of each plot in the color corresponding to their associated curve. All models were random forest classifiers trained using data labeled using a trichotomous labeling scheme with efficient and inefficient efficacy thresholds of $<25\%$ and $\geq60\%$ respectively (REF). Random background (grey) depicting model with no predictive power, was generated by evaluating model on a dataset with randomly shuffled efficacy labels. B Same as A but for model build using dataset split by gene. 
}
    \label{fig:Figure† 3}
\end{figure}

Recent advances in AI-based natural language processing have produced a variety of deep embedding methods for encoding words and text. These methods can also be applied to nucleotide sequences, which represent a genetic language (REF: application of embedding methods to nucleotides but not RNA). Deep embeddings capture complex contextual information and sequence motif relationships, enabling a richer representation of the siRNA targeting environment. We explored the impact of four deep embedding methods on supervised learning performance: Deep Word2Vec Continuous Bag-of-Words (CBOW), Deep FastText CBOW, Deep Word2Vec Skip-Gram, and Deep FastText Skip-Gram (REFs for each method) (Figure \ref{fig:Figure† 2}F-G). These approaches use deep neural networks to encode sequence information as multidimensional vectors, capturing complex intra- and inter-sequence interactions.

The choice of data encoding method had a profound impact: all deep embedding methods substantially outperformed one-hot encoding (Figures† 3A and 3C–E), indicating that traditional approaches fail to capture significant biologically relevant information. Since the same supervised learning model was used across all comparisons, these results underscore the critical role of data representation in predictive performance (TODO: $F1$-scores: XXX vs. XXX, XXX, and XXX; $\sim$0.7 for one-hot encoding on the endogenous dataset, respectively). To our knowledge, this is the first application of advanced deep embedding methods to small RNA models in the context of therapeutic development, and specifically, the first application to siRNA design.

\subsection{†Supervised models underperform when predicting siRNA efficacy for unseen target genes}

Using the same dataset, we performed a new partitioning strategy, maintaining the 75\% training and 25\% testing distribution. However, in this case, we separated the data by gene targets, while still stratifying by efficacy class to preserve similar numbers of functional and non-functional siRNAs in both sets. This ensured an efficacy distribution closely comparable to the one used in the initial random splits (Figure \ref{fig:Figure† 1}F–G). We then rebuilt the models using the same optimized parameters and sequence embedding methods as for the randomly split models (TODO: see XX – within manuscript). 

The model was trained 10 times, with results averaged (Figure \ref{fig:Figure† 3}F-J). A random control model showed no predictive power. Interestingly, the model maintained similar performance on the test set (i.e., sequences from the same genes used in training, $F1$-score $\approx$ 0.64). However, performance dropped dramatically when evaluated on the external dataset composed of sequences from an entirely different set of target genes (red curve, $F1$-score $\approx$ 0.2). Although the model performed slightly better than random, the loss in predictive power for the unseen genes ($F1$ = 0.2 vs. $F1$ = 0.73; Figure \ref{fig:Figure† 3}F–J) was striking—even when applying advanced deep embedding methods. 

The difference in performance on the “unseen” vs “seen” genes showed the limitation of the supervised model to generalize on new genes. These results also highlight a critical limitation: prediction performance based on randomly split datasets without separating the source genes between the training and test sets, may significantly overestimate real-world utility due to potential information leakage. By leveraging the high gene target diversity in our dataset, we thus uncovered a fundamental limitation in current siRNA efficacy prediction approaches—one likely shared by most existing siRNA design algorithms.




\section{Supervised Learning Models for fully modified siRNAs evaluated in reporter context}

\subsection{TODO: Random forest model trained to siRNAs evaluated with DualGlo Reporter Assay}

\subsection{**Use of reporter assay data builds a better predictive model for fully chemically modified siRNA efficacy than native context data}

Because efficacy data from reporter assays explicitly describes the ability of RISC to silence its target independent of native context factors, it might be well suited to train algorithms predicting the RISC competence of siRNA sequences. To test this hypothesis, we built predictive models trained on the reporter assay data for sequences tested in the Asymmetric $2^\prime$-OMe/-F pattern (Figure \ref{fig:Figure** 10}). These sequences are not biased by targeting location, this pattern better accommodates RISC loading, and asymmetric and blunt siRNA structures perform similarly. To build the models, we used a trichotomous partitioning method and random forest (RF) Machine Learning (ML) as described in Monopoli et al. \cite{monopoli_asymmetric_2023} (see Methods), using single bases at each position in the target sequence as a feature. We chose these methods because they have previously demonstrated suitability for small datasets \cite{monopoli_asymmetric_2023}. For each sequence, 50 nts (i.e., the 20-nt target site and 15-nt regions on each side of it) were extracted to train the models (see Methods). We chose to include the sequences flanking the target site because high Adenine/Uracil (A/U) content in these regions is an important feature of effective siRNAs, likely because it opens mRNA secondary structure and makes it available for interactions with RISC \cite{shmushkovich_functional_2018}. Notably, the siRNAs evaluated here might generally be performing better in the context of the reporter assay because the plasmid inserts include only the 20mer target sequences strung together, which contain <40\% G’s and C’s.


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{NAR 2025 Figure 10.pdf}
    \caption{\textbf{Machine Learning models trained on reporter assay data predict RISC- competence for fully chemically modified siRNAs. }(\textbf{A-C, left panels}) siRNA (Asymmetric $2^\prime$-OMe/-F pattern) target silencing results (n=3, mean ± SD) for (\textbf{A}) the full dataset in a reporter context used to create the models and for (\textbf{B-C}) external datasets used to evaluate the models from (\textbf{B}) reporter or (\textbf{C}) native assays. Cells treated for 72 hours. Target expression levels measured using the QuantiGene 2.0 RNA Assay (native) or DualGlo Luciferase Assay System (reporter) and calculated as percentage of untreated control. Dotted lines mark thresholds used for effective and ineffective siRNAs. (\textbf{A-C, right panels}) $AUCPR_{adj}$. values plotted and statistics shown for each of the models generated from the training datasets (85\% of the full dataset) for (\textbf{Aii}) 10-fold cross validations on the training datasets, and (\textbf{Aiii}) final model performances on the holdout datasets (15\% of the full dataset), (\textbf{Bii}) reporter assay derived external dataset, and (\textbf{Cii}) native assay derived external dataset.
}
    \label{fig:Figure** 10}
\end{figure}




The analysis used two cutoffs to classify the 50-nt sequences into effective or ineffective groups reflecting biologically acceptable thresholds for effective and ineffective siRNAs (i.e., those resulting in $\leq35\%$ and $>55\%$ target expression, respectively) (Figure \ref{fig:Figure** 10}Ai). These classified data were separated into model training and holdout sets, with equal distributions of effective and ineffective siRNAs in each set. This segmentation of the data was repeated 1000 times. Each holdout set consists of 15\% of the dataset, is excluded from model training, and is used to evaluate model performance, which is assessed by a Precision-Recall ($PR$) curve. Precision represents the percentage of siRNAs correctly predicted to be effective with respect to all siRNAs predicted to be effective. Recall depicts the percentage of siRNAs correctly predicted as effective with respect to all effective siRNAs in the dataset. High precision (i.e., low number of false positives) is prioritized over high recall (i.e., low number of false negatives) because the goal of the predictive algorithm is to correctly identify effective siRNAs, not necessarily all possible effective siRNAs. Nevertheless, both parameters are important, which is why a higher area under the precision-recall curve ($AUCPR$) generally indicates better model performance. However, this metric can be artificially inflated for models trained on different datasets because, at a certain threshold, a dataset with a higher proportion of effective sequences will have a higher $AUCPR$. To account for this, model performances were assessed using an adjusted metric called $AUCPR_{adj}$, which is defined by subtracting the area defined by precision at maximum recall \cite{monopoli_asymmetric_2023}.

To determine whether the datasets and cutoffs are appropriate for model building, $K$-fold cross-validations (right panel, $K=10$) were performed on each of the 1000 training datasets, wherein the data were randomly split into ten different groups and a model was trained on nine of those groups and evaluated on one of them iteratively. This provides a means to identify whether there are biases in the training data introduced by features in small numbers of sequences that might negatively impact algorithm performance before building the final models. Figure \ref{fig:Figure** 10}Aii plots results for 10-fold cross-validation of each training dataset, which are high and relatively consistent across all 1000 models, supporting the use of the selected cutoffs for final model building.

After using the training sets to generate models, models were evaluated using the holdout dataset (Figure \ref{fig:Figure** 10}Aiii), an external dataset derived from reporter assay data containing fifty SiRNA sequences with 14 different targets (Figure \ref{fig:Figure** 10}Bi), and an external dataset derived from native (QuantiGene) assay data with more than one hundred siRNA sequences targeting six different genes in four cell lines (Figure \ref{fig:Figure** 10}Ci). Our algorithms showed reasonable predictive power for the holdout (average $AUCPR_{adj}$ = 0.2061, Figure \ref{fig:Figure** 10}Aiii) and external reporter (average $AUCPR_{adj}$ = 0.5675, Figure \ref{fig:Figure** 10}Bii) datasets, but performed worse when tested on the external native dataset (average $AUCPR_{adj}$ = 0.08182, Figure \ref{fig:Figure** 10}Cii).
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{NAR 2025 Supplemental Figure 8.png}
    \caption{ \textbf{Machine Learning models trained on native assay data poorly predict fully chemically modified siRNA efficacy for other targets in external dataset. }(A and B, left panels) siRNA (Asymmetric $2^\prime$-OMe/-F pattern) target silencing results (n=3, mean \# SD) for (\textbf{A}) the full dataset in a native context used to create the models and for (\textbf{B}) the external dataset excluded from model building derived from native assay. Cells treated for 72 hours. Target mRNA expression levels measured using the QuantiGene 2.0 RNA Assay and calculated as percentage of untreated control. Dotted lines mark thresholds used for effective and ineffective siRNAs. (A and B, right panels) $AUCPR_{adj}$ values plotted and statistics shown for each of the models generated from the training datasets (85\% of the full dataset) for (Aii) 10-fold cross validations on the training datasets, and (Aiii) final model performances on the holdout datasets (15\% of the full dataset) and (Bii) native assay derived external dataset.
}
    \label{fig:Supplemental Figure** 8}
\end{figure}
To better predict efficacy in a native context, we built models using our native dataset. While the hit rate for this dataset was low (Table** 1, Original Sequences, Native Context, Asymmetric $2^\prime$-OMe/-F), the numbers were reasonable enough to perform a similar analysis. We built models using both the full dataset (Figure \ref{fig:Supplemental Figure** 8}Ai) and the filtered dataset that includes only siRNAs that target prominently expressed isoforms according to RNA- and 3P-seq data (see Methods) (Figure \ref{fig:Supplemental Figure** 9}Ai). Results for 10-fold cross-validations were acceptable for both datasets (Figures \ref{fig:Supplemental Figure** 8}Aii and \ref{fig:Supplemental Figure** 9}Aii). The models built on the full dataset performed worse than the models built on the filtered dataset when evaluated on the holdout sets (average $AUCPR_{adj}$ =0.1421 versus average $AUCPR_{adj}$=0.2586, Figures \ref{fig:Supplemental Figure** 8}Aiii and \ref{fig:Supplemental Figure** 9}Aiii, right panels). Based on our earlier analyses, we know that the full dataset contains improperly classified sequences, i.e., sequences that are effective but appear ineffective because they target underrepresented isoforms in SH-SYSY cells. Removing such sequences improves the model, suggesting they impede the construction of a model that can define effective siRNAs targeting the four genes tested. We tested each model type on an external dataset derived from native assay data and observed that both performed poorly (average $AUCPR_{adj}$ = 0.01868 for the full native dataset and average $AUCPR_{adj}$ = 0.03935 for the filtered native dataset, Figures \ref{fig:Supplemental Figure** 8}B and \ref{fig:Supplemental Figure** 9}B).
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{NAR 2025 Supplemental Figure 9.pdf}
    \caption{\textbf{Machine Learning models trained on native assay data filtered for siRNAs targeting prominently expressed target regions poorly predict fully chemically modified siNA efficacy for other targets in external dataset} (A and B, left panels) siRNA (Asymmetric $2^\prime$-OMe/-F pattern) target silencing results (n=3, mean \# SD) for (\textbf{A}) the full dataset in a native context used to create the models and for (\textbf{B}) the external dataset excluded from model building derived from native assay. Cells treated for 72 hours. Target mRNA expression levels measured using the QuantiGene 2.0 RNA Assay and calculated as percentage of untreated control. Dotted lines mark thresholds used for effective and ineffective siRNAs. (A and B, right panels) $AUCPR_{adj}$. values plotted and statistics shown for each of the models generated from the training datasets (85\% of the full dataset) for (Ail) 10-fold cross validations on the training datasets, and (Aiii) final model performances on the holdout datasets (15\% of the full dataset) and (Bii) native assay derived external dataset.
}
    \label{fig:Supplemental Figure** 9}
\end{figure}

Notably, the hits in the filtered, native dataset constitute 20\% of the total number of sequences, while the hits in the reporter dataset constitute 42\%. To clarify whether the lower performance of the predictive model trained on the filtered, native dataset was due to the smaller proportion of true hits, we randomly under-sampled the true hits in the reporter dataset to match the proportion of true hits in the native, filtered dataset and built new models (Figure \ref{fig:Supplemental Figure** 10}). Similar to the models trained on the full reporter dataset, these models performed relatively well on the external reporter dataset (average $AUCPR_{adj}$ = 0.3789,  Figure \ref{fig:Supplemental Figure** 10}B) and worse when tested on the external native dataset (average $AUCPR_{adj}$ = 0.04339, Figure \ref{fig:Supplemental Figure** 10}C). This suggests that model performances were not dependent on the proportions of hits in the training data.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{NAR 2025 Supplemental Figure 10.png}
    \caption{\textbf{Machine Learning models trained on reporter assay data under sampled to match the proportion of true hits in the native, filtered dataset predict RISC-competence for fully chemically modified siRNAs. }(A-C, left panels) siRNA (Asymmetric $2^\prime$-OMe/-F pattern) target silencing results (n=3, mean ‡ SD) for (\textbf{A}) the full dataset in a reporter context used to create the models and for (B-C) external datasets used to evaluate the models from (\textbf{B}) reporter or (\textbf{C}) native assays. Cells treated for 72 hours. Target expression levels measured using the QuantiGene 2.0 RNA Assay (native) or DualGlo Luciferase Assay System (reporter) and calculated as percentage of untreated control. Dotted lines mark thresholds used for effective and ineffective siRNAs. (A-C, right panels) $AUCPR_{adj}$. values plotted and statistics shown for each of the models generated from the training datasets (85\% of the full dataset) for (Aii) 10-fold cross validations on the training datasets, and (Aiii) final model performances on the holdout datasets (15\% of the full dataset), (Bii) reporter assay derived external dataset, and (Cii) native assay derived external dataset.
}
    \label{fig:Supplemental Figure** 10}
\end{figure}

Collectively, these data suggest reporter-derived data are well suited for building models to predict RISC-competence of fully chemically modified siRNAs, but not to predict efficacy in a native environment because there are factors impacting efficacy that cannot be accounted for using only the target sequence as a feature.

Finally, we present a model workflow for the successful design of chemically modified siRNAs (Figure** 11). Here we show the steps, from informatically selecting target sequences to analyzing the target transcript isoform usage in the context of a biologically relevant cell line and validating assays for the measurement of siRNA activity, to screening for hit compounds, and finally, to validating and choosing a lead compound using dose response experiments. This workflow provides a foundation from which to begin, but other steps, such as testing an siRNA "walk" around hit compounds and validating lead compounds in the tissue of interest in vivo can also be included in the screening and lead selection workflow.




\section{TODO: Other Supervised model fittings (if can find them)}
\subsection{TODO: Support Vector Machines}
\subsection{TODO: Support Vector Regression}
\subsection{TODO: Logistic Regression}


\chapter{SEMI-SUPERVISED MACHINE LEARNING MODELS FOR siRNA EFFICACY PREDICTION}
\section{Semi-Supervised Learning for siRNAs Evaluated in Native Context}
\subsection{†Semi-Supervised Learning enables remarkable siRNA prediction accuracy in unseen target context}

Predicting siRNA efficacy on novel genes (those unseen by the model) has been demonstrated to be a highly challenging problem. In fact, no existing siRNA prediction models have shown consistent success in this task (REFs). While supervised learning performance typically improves with additional training data, our ability to expand the labeled dataset is substantially limited by experimental throughput. As a result, supervised learning has reached its limits in this context. To overcome this, we introduced a new semi-supervised learning methodology that leveraged a large number of siRNAs with unknown efficacy data generated from the transcriptome. The core principle of semi-supervised learning is its ability to utilize large amounts of unlabeled data to better define class boundaries, thereby improving classifier accuracy (REFs).
Recently the use of semi-supervised learning was introduced as a promising alternative in several biological fields (REFs). We have previously applied this methodology for the prediction of the mutation and alternative splicing effects on protein-protein interactions with significantly improved model performance \cite{narykov_predicting_2021,zhao_determining_2014}. The ability of semi-supervised models to integrate both labeled and unlabeled data will allow us to use both the experimentally validated and computationally generated siRNA sequences, creating a powerful framework for improving the prediction of siRNA silencing potency.
This siRNA design process is unique – it utilizes the full space of theoretically computable siRNA target sequences (Figure \ref{fig:Figure† 4}A). By applying a 20-nucleotide sliding window across the transcriptome, a comprehensive set of candidate siRNAs can be generated with TODO: $\sim$44M theoretical siRNAs existing for 52 genes in our dataset. This process yields a vast corpus of unlabeled sequences – those for which the nucleotide sequence is known, but the silencing efficacy has not been experimentally determined. These sequences possess intrinsic structural and compositional features, including surrounding sequence environment information, that can inform models of siRNA efficacy (see Methods Chapter \ref{met:TODO}for additional details). 


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{MONOPOLI 2025 - Figure 4. Semi-Supervised schema and model performance per gene and cross-species.png}
    \caption{\textbf{Applying semi-supervised learning to develop highly predictive, species-specific siRNA efficacy prediction model.} \textbf{A} Schematic describing process for generating unlabeled siRNAs from a species transcriptome. \textbf{B-G} Precision-Recall curves depicting performance of semi-supervised learning model built with (teal) test and (red) external data split by gene for different sequence feature encoding methods (encoding method indicated at top of each plot). Human siRNA efficacy data used for model building described in Figure \ref{fig:Figure† 1}. Each curve indicates an average of ten rounds of model fitting. Confidence intervals depict the range of standard deviations of curves following ten rounds of model fitting. F-scores averaged over ten rounds of model fitting are shown in the top right corner of each plot in the color corresponding to their associated curve. All models were semi-supervised random forest classifiers trained using data labeled using a trichotomous labeling scheme with efficient and inefficient efficacy thresholds of $<25\%$ and $\geq60\%$ respectively (REF). Random background (grey) depicting model with no predictive power, was generated by evaluating model on a dataset with randomly shuffled efficacy labels. \textbf{H} Precision-Recall curves depicting performance of human semi-supervised learning models averaged over ten rounds of model fitting evaluated on human data. \textbf{I} The same human-trained model from H evaluated on mouse data. \textbf{J} Semi-supervised model built using mouse data and evaluated using human data. \textbf{K} Same mouse-trained model from J evaluated on mouse data. Human siRNA efficacy data used for model building described in Figure \ref{fig:Figure† 1}, mouse siRNA efficacy data used for model building described in TODO: Supplemental Figure S2. All models were built using GloVe encoded sequence data. Each curve indicates an average of ten rounds of model fitting. Confidence intervals depict the range of standard deviations of curves following ten rounds of model fitting. F-scores averaged over ten rounds of model fitting are shown in the top right corner of each plot in the color corresponding to their associated curve. All models were semi-supervised random forest classifiers trained using data labeled using a trichotomous labeling scheme with efficient and inefficient efficacy thresholds of $<25\%$ and $\geq60\%$respectively for human data, and $<35\%$ and $\geq70\%$ respectively for mouse data. }
    \label{fig:Figure† 4}
\end{figure}

Here, we successfully developed and trained a semi-supervised learning model using semi-supervised random forest method (Figure \ref{fig:Figure† 4}A; TODO: Figure† SX - semi-supervised schematic). For our model, we generated a set of 180,000 randomly sampled unlabeled siRNA sequences from the human transcriptome, representing $\sim$0.5\% of all theoretically possible siRNAs (TODO: Figure† SY – UMAP). This results in a $\sim$60-fold increase of the dataset size compared to the original training set, a scale comparable to previously suggested ratio of unlabeled and labeled dataset (Figure \ref{fig:Figure† 4}A; REF). Five semi-supervised learning models using the same sequence feature representation types as the supervised models (TODO: REF section in paper) were then trained using the labeled data in combination with the unlabeled data (Figure \ref{fig:Figure† 4}C-G; see Methods Chapter \ref{met:TODO}). In addition, to better capture relationships across this large, transcriptome-derived dataset, we explored a sixth sequence encoding method: Global Vector Embeddings (GloVe), a deep embedding approach that models sequence similarity based on global co-occurrence patterns (Figure \ref{fig:Figure† 4}B) \cite{pennington_glove_2014}. Given the scale and transcriptomic nature of the unlabeled data, GloVe was particularly well-suited for this application. 

Data were split based on the gene origin of the siRNAs: both unlabeled and labeled data present in the training dataset did not contain gene targets present in the evaluation dataset and vice versa. The cross-validation of the semi-supervised models showed a significant performance improvement compared to supervised models: $F1$-score of 0.77 for the best performing model (Figure \ref{fig:Figure† 4}B) versus 0.64 for the supervised model. More importantly, the evaluation showed that we drastically improved performance on the external dataset composed entirely of the unseen target genes achieving an $F1$-score of 0.68 [as compared to $F1$-score of 0.33 for the best supervised model (Figure \ref{fig:Figure† 3}H)]. Notably, even one-hot encoding benefited from the semi-supervised approach (Figure \ref{fig:Figure† 4}D). GloVe embedding yet again yielded the highest performance on the external test set (Figure \ref{fig:Figure† 4}B). 
These results demonstrate the successful development of the first high-accuracy model for predicting the efficacy of fully modified therapeutic siRNAs that is capable of generalizing to the biologically critical task of efficacy prediction on unseen target genes. Following further optimization (see Methods and Figure \ref{fig:Figure† S5}), we advanced this model for practical application in therapeutic siRNA design and integrated it into a comprehensive siRNA design algorithm.




\subsection{†TODO: Species-specific performance of the semi-supervised model}
Development of therapeutic siRNA necessitate evaluation of efficacy and safety in animal models. Thus, identification of compounds active in in other species is part of the development process, with mouse being one of the primary models used in preclinical development (REF). The RISC mechanism is highly conserved across mammalian species (REFs) and thus the methods for selecting potent siRNAs are commonly believed to be applicable across species (REFs). 

We therefore explore the human-trained model ability to predict mouse siRNA efficacy. Figure \ref{fig:Figure† 4}H shows performance of human transcriptomic trained semi-supervised model on the independent human data set. It shows excellent predictive power (TODO: xxxx> xxx vs control xxx). When applying the same model to mouse data, surprisingly, the performance was profoundly reduced (xxxx, vs xxx for random Figure \ref{fig:Figure† 4}I). While there is some predictive power maintained it is as low as one demonstrated by the one-hot encoding in a context of simplest supervise model (TODO: xxxxx $F1-\sim$ 025, Figure \ref{fig:Figure† 3}G). This indicates that by changing the genomic context we effectively lost all the contextual improvements brought using semi supervised learning and optimized feature encoding.

We then evaluated if this unexpected observation may be related to the limitation of the mouse dataset. Using established model fitting parameters (see methods) we trained the semi-supervised model on mouse data using mouse non-labeled transcriptomics information. The new mouse-trained model performed well on the mouse external test set (Figure \ref{fig:Figure† 4}K) indicating that the loss of performance of the human transcriptomics trained data is not due to the dataset quality. Similarly, the mouse-trained model lost effectively most of predictive power when evaluated on human dataset (Figure \ref{fig:Figure† 4}J).  Interestingly, the data set was enriched in cross-species homologs (Supplemental Table† SI) and thus species related transcriptomics context beyond the target identify is likely responsible for the contextual impact. These results indicate that the transcriptome information captured by the AI based model, driving predictive power is species specific. 



\subsection{†TODO:Case Study: Application to select novel functional siRNAs for key therapeutic targets}


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{MONOPOLI 2025 - Figure 5. Experimental evaluation of model.png}
    \caption{\textbf{Application of Semi-Supervised Model in Developing Potent Therapeutic siRNAs and Model Incorporated into siRNA Design Algorithm for Public use on the Web.} \textbf{A} Targeting positions for siRNAs selected for synthesis and endogenous target silencing evaluation. Gene name indicated at left for the selected transcripts lengths indicated below ($BCAM: NM_005581, GYS1: NM_002103, MLH1: NM_000249, MSH3: NM_002439$). Flags are positioned to scale within the target transcripts with flag color indicating the efficacy prediction by the semi-supervised model green indicating efficient and grey flags inefficient (see key top left). Flags are labeled above as described at the top left with target position and corresponding probability score outputted by the semi-supervised model above it. Gene bars are scaled per the target length with positions indicated at the bottom of each target bar. \textbf{B} Endogenous target knockdown efficacy of synthesized siRNAs selected by the semi-supervised model determined by branched DNA assay (see Methods) (y-axis) plotted with respect to semi-supervised model probability score (x-axis). Markers are colored by target as indicated at top right. Vertical dashed line indicates probability threshold applied for classifying model predictions as predicted efficient ($\geq0.50$) or predicted inefficient ($<0.5$). Horizontal dashed line indicates target expression threshold selected to classify siRNAs as functional ($\geq35\%$) or nonfunctional ($>35\%$). \textbf{C} Contingency table summarizing the semi-supervised model prediction performance based on the data presented in B. \textbf{D} Schematic of siRNA design algorithm incorporating semi-supervised model that is publicly available on the web enabling simplified design and selection of therapeutic siRNAs.}
    \label{fig:Figure† 5}
\end{figure}

\section{Semi-Supervised Learning for siRNAs Evaluated in Reporter Context}
% NOTE: this section may be removed
\subsection{TODO: Semi-Supervised Random forest model trained to siRNAs evaluated with DualGlo Reporter Assay}


\chapter{†TODO:ALGORITHM FOR THE DESIGN AND SELECTION OF POTENT THERAPEUTIC SIRNAS}


\chapter{†TODO:DEVELOPING A WEB PORTAL MAKING SIRNA DESIGN ALGORITHMS ACCESSIBLE}


\chapter{METHODS}

\section{Data Processing}

\subsection{†Efficacy Data Processing: using a trichotomous schema to identify efficient and nonefficient siRNAs for model building}

Machine learning and other AI techniques have great power for predicting challenging biological problems in drug discovery, however a major barrier is the need for very large datasets to produce reliable models. Obtaining fully modified (and thus therapeutically relevant) siRNA endogenous efficacies in cells is challenging and expensive to conduct at a high throughput, thus currently no such datasets exist publicly to our knowledge. Compiling such a large dataset purpose built solely for siRNA model building would be infeasible to perform in a high throughput fashion with resources available to most academic labs. While datasets for nonmodified siRNAs evaluated using reporter (and thus not endogenous) assays have been performed in such a setting \cite{huesken_design_2005}, to our knowledge no such datasets exist publicly for endogenously evaluated siRNAs (which we show is critical to model development as the endogenous transcript environment drives much of siRNA efficacy). Thus data were compiled in the course of screening siRNAs for concomitant studies. So while many aspects of experimental conditions were maintained constant for all 2500 siRNAs in our dataset (chemical scaffold, mRNA quantification method (QuantiGene), siRNA treatment conditions, independent triplicate assessment), some components (cell line, small changes in media/buffer compositions, etc.) could not be. These factors in addition to the endogenous nature of the assay itself, produces a dataset with a large amount of noise. This noise makes it impossible to distinguish siRNAs from functional and nonfunctional when close to the classification threshold (Figure \ref{fig:Figure† 1}B compare bars close to the dotted lined thresholds) \cite{monopoli_asymmetric_2023}. Thus, a trichotomous partitioning scheme was utilized for classification in this paper, which we describe previously \cite{monopoli_asymmetric_2023}.

\subsubsection{†EFFICACY DATA PROCESSING AND NORMALIZATION}

Known differential target transcript nuclear localization and other cellular factors (alternative splicing, efficiency of the assay, etc.) create bias in the efficacy data \cite{ly_visualization_2017}. To minimize these biases, the data were max-min normalized within each gene target (Equation \ref{eq:normalize}); for simplicity of computational calculations, siRNAs with 0\% target gene expression remaining after normalizing (i.e., the siRNAs with the highest efficiency for their gene target), were set to 1\% target gene expression remaining (Figure \ref{fig:Figure† 1}A. Unnormalized human siRNA efficacy data are shown as percent of native mRNA expression remaining normalized to housekeeping gene, measured by QuantiGene assay (Affymetrix) (REF) in Supplemental Figure† S1A and S1B. The same normalization procedure was performed with the mouse targeting siRNAs (Figure† S2); Supplemental Figure† S1C-D show the same data for mouse targeting siRNAs. siRNA efficacy data are presented in Supplemental Table† S1.


\begin{equation}\label{eq:normalize}
\begin{matrix}Normalized\ Target\ Gene\ Expression\\for\ siRNA\ i\ targeting\ gene\ g\\\end{matrix}=\ {x_{i\ norm}}_g=\ 100\%\ast\frac{{x_i}_g-{x_{min}}_g}{{x_{min}}_g-{x_{max}}_g}\ \  
\end{equation}

\subsubsection{†EFFICACY DATA PARTITIONING BY TRICHOTOMOUS CLASSIFICATION}
Data were classified by siRNA efficacy using a trichotomous thresholding method previously described \cite{monopoli_asymmetric_2023} with efficient siRNAs defined as those with target gene expression remaining less than or equal to 25\% ($\sim$447 siRNAs $\sim$ 40\%), inefficient greater than equal to 60\% ($\sim$309 siRNAs $\sim$ 32\%), and undefined siRNAs with efficacies greater than 25\% and less than 60\% ($\sim$466 siRNAs $\sim$ 28\%) (Figure \ref{fig:Figure† 1}B).


\subsection{†Target Transcript Sequence Data processing}
Extensive studies of siRNA biology (TODO: REFS) along with existing models (albeit for nonmodified siRNAs) (TODO: REFs) indicate the critical role target sequence plays in driving siRNA efficacy and so we chose to utilize sequence as the primary source of data in our model. Other computational models for siRNA efficacy prediction have considered factors such as thermodynamics and target secondary structure among others, (TODO: REFS) however the contribution of these factors to model performance is not clearcut, and they further are inherently described in the sequence itself and therefore we chose to simplify our model with the reasoning that a more powerful AI model like the one used in this study likely can account for these factors implicitly. 

\subsubsection{†SEQUENCE DATA PROCESSING}
All siRNA target sequence data were cleaned to ensure all sequences contained a 20nt Targeting Region: the 20nt region on target mRNA transcript directly interacting with RISC (REF), with a matching 16nt Homology Region (positions 3-18 on Target sequence). 

Data were cleaned to ensure no duplicates. Note that in some cases duplicate siRNAs were evaluated across species in human as well as mouse. With such large flanking sequence lengths explored (up to 100nts) some target sites falling close to the $5^\prime$ or $3^\prime$ end of their target transcript would not have a full 100nt flanking sequence on each side. Since several of these siRNAs showed high silencing activity (Supplemental Table† S1) and these data represented only 3\% of the dataset, we opted to include these informative data and padded the sequences as described below.

To ensure high diversity and no major biases in the siRNA sequences, sequence similarities of the 20nt target sequences for all 2475 siRNAs were evaluated by computing the Levenshtein Distance \cite{levenshtein_binary_1966} across all sequences, pairwise using the distance method from the Levenshtein Python package (REF https://github.com/rapidfuzz/Levenshtein/tree/main). No significant similarities between distances were seen (Supplemental Figure† S1E). This was repeated with the mouse data with the same result of no significant sequence biases (Supplemental Figure† S1F). 

\subsubsection{†FLANKING SEQUENCE EXTRACTION}
Flanking sequence data for model building were obtained from the target species transcriptome (NCBI RefSeq; \cite{oleary_reference_2016}. The 16nt Homology Region (positions 3-17 on Target sequence) for each siRNA was used to search the transcriptome to identify the target site position within the transcriptome. To identify the Target Site position for each siRNA, it’s 16nt Homology Region was walked along each transcript in the transcriptome to identify any positions with perfect complementarity. For instances of multiple isoforms for a target gene, the target site of the most highly expressed isoform was selected. While none were identified in this dataset, siRNAs targeting multiple genes would be deemed cross-reactive and would be excluded from the dataset. This additional search ensured that no cross-reactive siRNAs (targeting more than one host gene) were included in the dataset and ensured that flanking region sequences selected reflected those most highly expressed. Upon identification a Target Site, regions flanking this site were extracted both upstream and downstream (up to 100nts). Thus for the final model with 100nt flanking sequence lengths, for each siRNA efficacy datapoint, a corresponding sequence of 220nts (20nt Target Site + 100nt $5^\prime$ Flanking Sequence + 100nt $3^\prime$ Flanking Sequence) was obtained. This was repeated for all 2475 siRNAs. All siRNA sequence data: target, homology, and flanking regions, are included in Supplemental Table† S1. 
Sequences targeting within 100nts of the $5^\prime$ or $3^\prime$ end of the target transcript were padded with “X”’s to the appropriate flanking sequence length.




\section{Sequence Feature Encoding}\label{met:sequence feature encoding}
Sequence feature information includes nucleotide identity (A/U/C/G) and position within the target sequence and flanking region, which must be encoded (i.e., translated) into a numeric format for model fitting. One-hot encoding is predominantly used in sequence information analysis. It involves representing a sequence as an array of ones and zeros representing the presence or an absence of the nucleotide in a particular position. In this case all contextual biological information is lost (e.g., nucleotide relationships, sequence motifs, etc.). 

Recent advances in natural language processing (NLP) and AI have generated a variety of methods to efficiently encode text data while retaining meaning, syntactic relationships, and context (including hidden semantics) of words with high accuracy. These methods utilize neural networks to embed the text data, by expressing words as vectors in multidimensional space with relationships (context) between these vectors represented by numeric weights that are automatically learned with high accuracy by the neural network \cite{rosenblatt_perceptron_1958}. Biological sequence data including amino acid sequence and nucleotide sequence represent a form of genetic language and deep embedding methods have been successfully applied to encode biological sequence information \cite{littmann_protein_2021, mahmud_deep-wet_2024}. To our knowledge deep embeddings have not been applied in development of nucleic acid therapeutics. 

Several deep embedding methods were considered for our study and were selected for their high performance in prediction model applications, simplicity of implementation, and computational efficiency to enable fast model training. The deep embedding method Word2Vector was developed at Google in 2013 \cite{mikolov_distributed_2013}. This method utilizes a shallow neural network to embed words in vector space such that vectors (sequences) with more similar in meaning are located more closely together in space than those that are more dissimilar. The FastText deep embedding method was developed by a team at Facebook's AI Research (FAIR) lab in 2015 \cite{bojanowski_enriching_2017}. FastText embeds text information at the character level by breaking text up into subword n-grams where n is the number of characters. Words are then represented as an average of their character embeddings. This can often enable better encapsulation of similarities between distinct but highly related words (e.g., the words runner and running), however can be more computationally demanding to train when compared to Word2Vector embedding.

Both FastText and Word2Vec embedding methods utilize two main architectures to generate embedding vectors: Continuous Bag-of-Words (CBOW) and Skip-gram \cite{mikolov_efficient_2013}. The CBOW architecture utilizes the context (or surrounding words) to predict a target word, while the Skip-gram architecture utilizes a word to predict its context. We explored both embedding methods and architectures in sequence information encoding for building supervised siRNA efficacy prediction models resulting in the examination of the four deep embedding methods: Deep Word2Vector CBOW, Deep FastText CBOW, Deep Word2Vector Skip-Gram, and Deep FastText Skip-Gram. The impact of the data encoding methods was profound and all of them perform substantially better than one-hot-encoding (Figure \ref{fig:Figure† 3}), indicating that indeed a lot of biologically relevant sequence relational information is lost with conventional encoding methods. 
In addition, a sixth word embedding method, Global Vector Embeddings (GloVe), was considered for sequence embedding for semi-supervised siRNA efficacy prediction model development \cite{pennington_glove_2014}. This method produces vector representations of words in space based off of co-occurrences between words modeling similarities and relatedness of word pairs as a probability of their co-occurrence. While most applications of GloVe utilize a pre-trained version of the model trained on English text data, our application to nucleotide transcript sequence data necessitated training our own model (see below).
Code for encoding methods can be found in the supplementary materials (\textit{embedding\textunderscore methods.py}).


\subsection{†One-hot Encoding}\label{met:one-hot encoding}

One-hot encoding was performed in the standard way (REF One-hot encoding). Briefly, a dictionary was applied across each base in each sequence encoding each base with a corresponding numeric array: $A \rightarrow[1,0,0,0], U\rightarrow[0,1,0,0], C\rightarrow[0,0,1,0], G\rightarrow[0,0,0,1]$. The arrays were then flattened into a single sequence of 0’s and 1’s. This resulted in a sequence consisting of 220nts being encoded with a 1-dimmensional array of length 880, thus only the kmer size of 1 was considered with One-hot encoding due to computational intractability with larger kmer sizes. 

\subsection{†Deep Embedding}\label{met:deep embedding}

For all four deep embedding methods (Deep Word2Vector CBOW, Deep FastText CBOW, Deep Word2Vector Skip-Gram, Deep FastText Skip-Gram, and GloVe) sequences ($5^\prime$ and $3^\prime$ flanking regions + target site 20mer) were first broken into sets of Kmers using specified Kmer and Window Size parameter values (see Parameter Optimization) for final model building these values was set to 9nt and 1nt respectively. This resulted in each sequence being represented as an array of Kmers. For all deep embedding methods, the Kmers were treated as words, with individual sequences being treated as single sentences. For all deep embedding models, the resulting embeddings generated for each embedding were aggregated to generate the vector representation of the sequence data for each target sequence. This resulting vector representation was generated within the constraints of the Kmer (word) frequency cutoff parameter such that only Kmers that occurred with a frequency greater than that parameter were included. For the final supervised model the word frequency cutoff was set to 1. All encodings and embeddings were performed locally on a 2.3 GHz 8-Core Intel Core i9 laptop computer with a maximum run time of 4 hours for GloVe embedding.

\subsection{†Deep Word2Vector Continuous Bag-of-Words (CBOW) Embedding}\label{met:word2vector cbow}

To perform Deep Word2Vector CBOW embeddings the Word2Vec model from the Gensim Python package was utilized to train the model \cite{mikolov_efficient_2013,rehurek_software_2010}. Default settings for the Word2Vec model were selected for all but the following parameters. The $min\_count$ parameter was set to the specified Word Frequency Cutoff Parameter value (see Parameter Optimization), note that for final model building (after optimizing the parameters) this value was set to 1. The $window$ parameter, which determines the number of words to consider on each side for context, was set to 15 words as this value enables sufficient encapsulation of surrounding sequence information while maintaining computational tractability. Note that this window parameter is a Gensim package-specific parameter and is not related to the Window Size parameter utilized for generating Kmers from the sequence data. The $vector\_size$ parameter, which dictates the number of dimensions in space the Word2Vec model maps words onto, was set to 120 which provided reasonably high model performance while maintaining computational tractability and reasonable memory consumption. A vocabulary was built using the sequence Kmer arrays using the $build\_vocab$ method. The Word2Vec neural network model was then trained on the sequence data over 50 epochs. Following training, aggregate sentence vectors for each sequence were generated from the Kmers based on the Word2Vec model representation. The sentence vectors were then averaged for each sequence. The resulting arrays were utilized for siRNA efficacy prediction model training.

\subsection{†Deep Word2Vector Skip-Gram Embedding }\label{met:word2vector skip-gram}

This embedding was performed similarly to Deep Word2Vector CBOW embeddings, except that the Word2Vec model was configured for Skip-gram embedding rather than CBOW by setting the $sg$ parameter to 1. 

\subsection{†Deep FastText Continuous Bag-of-Words (CBOW) Embedding}\label{met:fasttext cbow}

The Deep FastText CBOW embeddings were performed utilizing the $fastText$ Python package \cite{bojanowski_enriching_2017}. The array of Kmers were first processed to the proper format for training with the $fastText$ package by concatenating the Kmers for each sequence into a single text file corpus with each sequence separated by a newline and kmers within each sequence separated by a single space on their respective lines. The sequence embedding model was then trained using this text coprpus as the input applying the $fastText$ module $train\_unsupervised$ method, which is designed for building word representation models. 


\subsection{†Deep FastText Skip-gram Embedding}\label{met:fasttext skip-gram}

Deep FastText Skip-Gram embedding was performed similarly to Deep FastText CBOW embeddings, except that the $fastText$ model was configured for Skip-gram embedding rather than CBOW by setting the $model$ parameter to “skipgram”. 


\subsection{†Global Vector Embedding (GloVe)}\label{met:glove}

GloVe embedding was performed utilizing the $GloVe-1.2$ package \cite{pennington_glove_2014}. A text file corpus was first generated using the Kmers such that Kmers were separated by a single space and each sequence was on a new line (For example corpus see Supplementary Materials file $kmer-9_windw-1_wfco-5_glove_corpus_sirnas-as-docs.txt$). A GloVe model was then trained on the corpus with default parameters (For example vectors see Supplementary Materials file $kmer-9_windw-1_wfco-5_glove_corpus_sirnas-as-docs_vectors.txt$). The resulting vectors were used as representation of their corresponding Kmers in the sequence data.


\section{Model Fitting}\label{met:model fitting}
\subsection{*/†Training Supervised Learning Classifier for siRNA Efficacy Computation}

When training the prediction model, both classification and regression were considered. A regression model fit the data poorly (Supplemental Figure† S7) we suspect the source of this error is due to a large proportion of noncontributory data in the form of siRNAs having only moderate silencing efficacy (shown as grey bars in Figure \ref{fig:Figure† 1}) contributing noise to the model. The cause of siRNA efficacy loss in this moderate efficiency group is likely manifold (RISC entry, cleavage, etc.) however it is not possible to determine the source of this decrease and so further studies would need to be performed. Fitting a simple binary classification model was difficult due to the noise inherent to the endogenous data, which creates an ambiguous region around classification thresholds. To overcome these challenges, a trichotomous classification scheme was utilized that was optimized to minimize the impacts of biologically ambiguous datapoints and also to overcome challenges with noise inherent to the nature of endogenous silencing data \cite{monopoli_asymmetric_2023}. Classification thresholds were selected as previously described \cite{monopoli_asymmetric_2023} resulting in a roughly equivalent split of data into three classes: Efficient (<25\% Target mRNA expression remaining [$\sim$782 siRNAs]), Inefficient (>60\% Target mRNA expression remaining [$\sim$853 siRNAs]), and Undefined (Target mRNA expression remaining $\geq25\%$ and $\leq60\%$ [$\sim$840 siRNAs]) (Figure \ref{fig:Figure† 1}B).

A random forest (RF) classifier was selected for initial supervised model training due to its rapid convergence to optimal performance with minimal training data, outperforming other nonlinear classifiers in training \cite{fernandez-delgado_we_2014}. RF operates by constructing an ensemble of decision trees that recursively partition the feature space to optimize class separation. In this context, RF models utilize nucleotide-level positional features from the siRNA target sequence to distinguish between efficient and inefficient siRNAs. RF is well-suited for high-dimensional feature spaces and can model higher-order feature interactions – such as sequence motifs—through its hierarchical tree structure, offering advantages over linear classifiers in capturing non-additive effects \cite{breiman_random_2001}. For the supervised classification task, deep learning models were not considered due to the limited size of the siRNA dataset.
The $RandomForestClassifier$ from the Scikit Learn ensemble Package was used for model fitting \cite{pedregosa_scikit-learn_2011} with the default parameters. After classifying and partitioning siRNA efficacy data, efficient and inefficient data were utilized for model building with target values set to 1 and 0 respectively to fit the model training formatting requirements.  Sequence data were encoded into a numeric format (see Methods: Nucleotide Sequence Encoding, Chapter \ref{met:sequence feature encoding}) before fitting the models.


\subsection{†Training Semi-Supervised Learning Classifier for siRNA Efficacy Computation}

Advanced machine learning methods have shown great power for developing highly predictive biological models (REF), however typically these methods require massive amounts of data (amounting to 10,000+ experimentally evaluated siRNAs), which is infeasible particularly at an academic lab scale. Excitingly, recent advances in AI-based modeling and computing throughput have propelled the development of new powerful techniques optimized for building predictive models with limited datasets eliminating the former requirement for prohibitively large datasets, providing the ability to develop incredibly powerful advanced ML models in biological context where obtaining large scale datasets is prohibitive. Semi-supervised learning is such a technique, that utilizes unlabeled data (siRNA sequences without known efficacies) in conjunction with the labeled experimental data to provide a boost in model predictive power (REF semi-supervised learning/SSRF). 
siRNA design is well suited to semi-supervised learning due to the inherent ability to easily synthesize unlabeled siRNA sequences by simply extracting 20nt sequences from the transcriptome. Adding this additional transcriptomic data provides information inherently present in the sequences, in a sense semi-supervised learning allows the unlabeled sequence data to “speak for themselves.” We hypothesize that the reason for the profound drop in performance on a gene-split data is due to missing gene specific information. We have decided to explore if addition of non-labeled data would compensate for this deficiency. We explored several methods of obtaining unlabeled data to add and narrowed down on whole human transcriptome. 

\subsubsection{†UNLABELED DATASET PREPARATION AND PROCESSING}
We utilized the the human Refseq Database Release 110 containing 19,884 genes and 129,740 transcriptional variants \cite{oleary_reference_2016}. From this information we generated a set with 24,750,000 theoretical siRNAs sequences with unknown efficacy by random sampling of all possible 20nt theoretical siRNA target sequences, which we defined as the unlabeled dataset (Figure \ref{fig:Figure† 4}). This 64-fold excess of unlabeled data over labeled is consistent with current semi-supervised application (REF). TODO: add details of random sampling method


\subsubsection{†SEMI-SUPERVISED CLASSIFIER TRAINING}
The $SelfTrainingClassifier$ from the Scikit Learn $semi\_supervised$ package was applied for semi-supervised model training \cite{pedregosa_scikit-learn_2011} utilizing a $RandomForestClassifier$ with default parameters as the estimator. After classifying and partitioning siRNA efficacy data, efficient and inefficient data were utilized for model building with target values set to 1 and 0 respectively to fit the model training formatting requirements. The unlabeled dataset is generated as described above. The undefined siRNA efficacy identified during data partitioning are also included in the unlabeled dataset (Figure \ref{fig:Figure† 1}B, grey bars). Sequence data, both labeled and unlabeled, were encoded before fitting the models.



\subsection{*$K$-fold cross-validation for model fitting}


\subsection{†TODO: METHODS VERSION - Pipeline simulating real-world application of siRNA Design through orthogonal dataset evaluation}



\subsection{†Parameter Optimization}\label{met:parameter optimization}
\subsubsection{†PARAMETER OPTIMIZATION OF THE SUPERVISED MODEL}
 A scheme describing the four primary parameters is presented in Figure \ref{fig:Figure† S5}A. Since no established parameter values are indicated in the literature, a broad range of values were explored for each parameter. Flanking sequence length, the region upstream and downstream of the target site, was considered from 0nts to 100nts as sequences in this region have previously been implicated in RISC entry and siRNA efficacy \cite{schubert_local_2005,shmushkovich_functional_2018,sun_sequence_2010} and to potentially capture longer range interactions in the prediction model. Kmer size, the length of the sequence fragment utilized when encoding the target sequence data, was explored from 1 to 20nts. Window size, the number of base position steps taken between kmers, was explored from 1 to 8nts. Kmer frequency cutoff, the minimum number of kmers required to be present in the dataset to be included when building embedding dictionaries (see Methods Chapter \ref{met:sequence feature encoding}) were considered from 1 to 10. Values greater than 10 were explored and showed poor performance and posed difficulty in fitting the model (data not shown). Parameter values were selected to provide a range exploring each parameter’s contribution within the context of biological implications while considering computational limitations; flanking regions beyond 100nts and larger window sizes, for example, were not considered for this reason. Each sequence feature encoding method was considered individually to capture any encoding-specific biases. Note that the nature of one-hot encoding, considering a single nucleotide individually, necessitates that the kmer size could not be adjusted, and therefore this parameter was not considered for this encoding method. 
 
Optimization was performed individually for each of the four parameters, holding all other parameters constant. Each was parameter evaluated using unique “sub partition triads” of the Training Dataset consisting of a Building Set (75\%, $\sim$1392 siRNAs), Parameter Optimization (PO) Set (10\%, $\sim$186 siRNAs), and Test Set (15\%, $\sim$278 siRNAs) (Figure \ref{fig:Figure† 2}B). Sub partition triads were generated by random shuffling and efficacy stratified. For each parameter, N triads were generated, one for each parameter value and thus 8 for flanking sequence length, 10 for Kmer size, 5 for window size, 5 for Kmer frequency cutoff. To evaluate single parameter values for supervised model development, a Building Set from (Figure \ref{fig:Figure† 2}B, green bar) is used to build a model applying the given parameter value, the model is then evaluated on the corresponding PO Set from the same sub partition triad (Figure \ref{fig:Figure† 2}B, yellow bar). To limit biases introduced by aberrations in the limited biological data and ensure stochastic model stability, this model building and PO evaluation process is repeated for a total of 25 times, shuffling the data in the PO and Building Set each time for each parameter value explored. Unlike other methods of partitioning where a portion of the data are only used once in the testing set, this method of random partitioning enables extension of parameter optimization to a much larger number of iterations while still incorporating all the data in the process, therefore better accommodating variations in the dataset. The performance, measured by $F1$-score, of the 25 models is averaged and compared across all values considered for the given parameter for each encoding method. The  final supervised model parameters were flanking sequence length = 100nts, Kmer size = 9nts, Window size = 1nt, and Kmer frequency cutoff of 1 (Figure \ref{fig:Figure† S5}B).



\subsubsection{†PARAMETER OPTIMIZATION OF THE SEMI-SUPERVISED MODEL }

Due to the large time and computational complexity of training the semi-supervised model, optimization was limited to only the best embedding (GloVe), fitting rounds were limited to 15, data were split by gene, and parameter values explored were limited slightly (Figure \ref{fig:Figure† S5}C). Generally the flanking sequence length showed a trend of increasing performance until 75nts after which a decrease is seen. The Kmer size showed optimal performance at 5nts and 20nts. Window size generally remained the same up to 3nts and then decreased performance substantially with larger sizes. Kmer frequency cutoff did not show major differences in performance. Due to the computational complexity of semi-supervised learning, when selecting top parameters we chose a Kmer size of 5nts over 20nts as models fit more quickly with this parameter (Figure \ref{fig:Figure† S5}C). Based on these results we selected the final model parameters for the semi-supervised model to be flanking sequence length = 75nts, Kmer size = 5nts, window size = 1nt, and Kmer frequency cutoff = 1. 


\section{†/*TODO: Model Performance Evaluation}\label{met:model performance eval}
\subsection{*TODO:Precision-Recall Curves and}\label{met:precision-recall curve}
\subsubsection{*Area Under the Precision-Recall Curve ($AUCPR$)}\label{met:AUCPR}
\subsubsection{TODO:Discerning Precision-Recall curves from Sensitivity vs Positive Predictive Power curves}
\subsection{*A novel scoring metric, $AUCPR_{adj}$, for model evaluation across two-threshold combinations}\label{met:AUCPRadj}






\subsection{TODO:Computing unachievable region to enable comparison of precision-recall curves across different classification thresholds}\label{met:unachievable region}
\subsection{†TODO:F1-Score}\label{met:f1-score}
\subsection{*Visualization of siRNA position-base weights driving models by proxy feature extraction} \ref{met:proxy feature extraction}
\subsection{†Applying Prediction Models to Generate Novel siRNAs}

\section{Designing viral-targeting siRNAs}\label{met:viral siRNA design}
\subsection{***Identification of Highly Conserved SARS-CoV-2 Regions for siRNA-Based Targeting}
SARS coronaviruses have caused multiple severe outbreaks in the last two decades \cite{piret_pandemics_2021, graham_decade_2013}. Like any virus, SARS-CoV-2 accumulates mutations that are naturally selected to enhance infectivity, adaptation to new hosts, escape from acquired natural, or vaccine-based immunity or drug resistance \cite{chakraborty_evolution_nodate, harvey_sars-cov-2_2021} The infectivity in terms of receptor engagement and entry of the virus is mainly defined by epitopes on the surface of the viral particle. Most antigens targeted for neutralizing antibody-mediated immunity are from the same regions \cite{lauring_genetic_2021, kannan_omicron_2022, hoffmann_sars-cov-2_2021, garcia-beltran_multiple_2021}. 

In contrast to neutralizing antibodies, targeting viral RNA allows access to the entire viral genome. We performed genomic alignments of SARS-CoV-2 variants from patients to the SARS- CoV-2 reference genome (population identity), as well as alignments of the SARS-CoV-2 reference genome to that of other coronaviruses (family identity). (Figure*** 1\textit{A }and \textit{SI Appendix}, Figure*** S1). We designed 108 siRNA sequences using a modified siRNA design algorithm similar to what was reported previously \cite{shmushkovich_functional_2018}. Targeting sites were distributed throughout the SARS-CoV-2 genome with twelve siRNAs per open reading frame (ORF) (Figure*** 1\textit{B}). A strong preference was given to siRNAs targeting regions with high family and population homology scores since highly conserved regions are less likely to tolerate mutation. More than 95\% of designed siRNAs had homology scores of >85\% at the family level and >99\% at the population level (Figure*** 1\textit{C}). 

Durable in vivo siRNA activity depends on full chemical stabilization \cite{hassler_comparison_2018} with the tolerance of chemical modification patterns showing significant sequence dependence \cite{shmushkovich_functional_2018}. To enable a seamless transition to in vivo studies, all the screens were done in the context of fully chemically modified siRNAs (Figure*** 1\textit{D}). All $2^\prime$-positions of ribose sugars of nucleotides were modified with $2^\prime$-\textit{O}-methyl ($2^\prime$-\textit{O}-Me) or $2^\prime$-fluoro ($2^\prime$-F groups), and terminal internucleotide linkages were metabolically stabilized with phosphorothioates. For in vitro screening, compounds were conjugated to cholesterol, which enables efficient uptake in all cell types \cite{alterman_hydrophobically_2015}. To allow testing and comparison of an independent mechanism of gene silencing, we also designed and synthesized 53 LNA gapmer ASOs (five or six ASOs per viral ORF). Full sequences and chemical modification patterns of all oligonucleotides used are shown in \textit{SI Appendix}, Table*** S1. 

\subsection{***Identification of Functional siRNAs and ASOs Targeting the SARS-CoV-2 Genome}
The 108 siRNAs and 53 ASOs were synthesized, and their identity was confirmed by LC–MS. To rapidly screen sequences, we engineered a panel of SARS-CoV-2 genome psiCHECK-2 reporter plasmids to contain the siRNA target sites within the mRNA for a luciferase reporter. Figure*** 1\textit{E }and \textit{SI Appendix}, Figure*** S2 show the results of the primary siRNA screens. 38\% (41 siRNAs) induced more than 50\% reporter silencing, while 8\% (9 siRNAs) induced more than 80\% reporter silencing and dose-dependent activity (Figure*** 1 \textit{E }and \textit{F}). For ASOs, most of the compounds were highly active and of similar efficacy to the siRNAs (\textit{SI Appendix}, Figure*** S3). 

There were no distinct differences in efficacy across regions of the viral genome. Top hits per target region showed subnanomolar IC50 in uptake without any delivery vehicle, indicating highly potent, clinical quality leads. Thus, the screen identified plentiful, highly conserved, fully chemically stabilized siRNAs and ASOs spanning the entire SARS-CoV-2 genome. While the reporter assays allowed for rapid screening and identification of hits, the lack of target sequence context (neighboring nucleotides, mRNA secondary structure, and localization) may have reduced the relevance of the siRNA efficacy predictions to the authentic viral sequence (see next paragraph). Future antiviral screens may be aided by the incorporation of target flanking regions in the reporter plasmid to understand the role of sequence context in the efficacy of siRNAs. 

\section{†Guide for designing and selecting potent siRNAs using Web Portal}



\section{Experimental Methods}

\subsection{‡/*Evaluating the efficacy of a panel of 356 partially chemically modified siRNAs in reporter context}

\subsection{**Evaluating efficacy of panel of 253 fully chemically modified siRNAs in reporter context}

\subsection{†Evaluating efficacy of a panel of 4227 fully chemically modified siRNAs in native context}





\chapter{TODO: DISCUSSION}\label{sec:discussion}

\section{FUTURE DIRECTIONS – TARGET ACCESSIBILITY}

Several models exist for siRNA efficacy prediction that utilize accessibility as a primary determinant. The SVM model presented by Lu and Mathews was trained on target site accessibility as a primary component (REF  Lu and Mathews, Nucleic Acids Research, 2008).  Accessibility was determined from free energies of binding of the siRNA guide to the target transcript using the OligoWalk algorithm (REF Mathews et al. 1999).  RNAxs is another siRNA design algorithm that considers target site accessibility, utilizing RNAplfold for the computation (REFs Bernhart, Hofacker, and Stadler 2006; Tafer et al. 2008). RNAxs is available on the web (http://rna.tbi.univie.ac.at/cgi-bin/RNAxs/RNAxs.cgi). With growth in the accuracy of RNA folding predictions, there is a wealth of information that can be gained by including this component into predictive modeling.


\section{Modification-specific models, are they needed?}



\section{A critical need: Bridging computation and RNA Biology (TODO: remove this section? or at least rephrase)}

With these advances a major limitation is communication/bridging between two research fields. The fields of machine learning and RNA biology are so complex that having knowledge in both fields to be scientifically successful is not possible without extensive collaboration between experts.  Critical is branching the fields of advanced computation and biomedical research, to provide insight into the vast (and growing) mathematic models with increasing power, available, because there are just so many now that a biologist or physician scientist is likely to be unaware of. Critical too is the extensive mechanistic knowledge of the biology and chemistry of the complex molecular mechanisms inside the cell as well as physiological mechanisms driving disease, provided by the biomedical expert. Understanding how to properly target a component or components of a biological pathway or mechanism to effectively and safely treat a disease is critical to drive success and not possible without the extensive knowledge and experience of the biomedical research experts. In addition the extensive computational expertise to ensure proper application of the model is critically served by the ML expert. Similarly, access to bench science to formally probe and evaluate computational models is critical lest the entire process is simply theoretical. Thus, as computational advances make biology more driven by computation, greater collaboration between these fields is critical to keep up and drive forward.













%\printbibliography








\end{document}

